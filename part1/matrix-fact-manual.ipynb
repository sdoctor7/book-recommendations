{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('../ratings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Subsets of Data for Part I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 subsets: 500 users / 20 books, 2000 users / 50 books, 10000 users / 100 books. Each has a train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pick_users_books(df, num_users, num_books):\n",
    "    user_counts = pd.DataFrame(df.user_id.value_counts()).sort_values('user_id', ascending=False)\n",
    "    top_10K_users = list(user_counts[0:num_users].index)\n",
    "    user_filtered_df = df[df.user_id.isin(top_10K_users)]\n",
    "    filtered_book_counts = pd.DataFrame(user_filtered_df.book_id.value_counts()).sort_values('book_id', \n",
    "                                                                                             ascending = False)\n",
    "    top_100_filtered_books = list(filtered_book_counts[0:num_books].index)\n",
    "    filtered_df = user_filtered_df[user_filtered_df.book_id.isin(top_100_filtered_books)]\n",
    "    train, test = train_test_split(filtered_df, test_size = 0.2, random_state=42)\n",
    "    return train, test\n",
    "    \n",
    "def get_all_subsets(df):\n",
    "    train_500_20, test_500_20 = pick_users_books(df, 500, 20)\n",
    "    train_2000_50, test_2000_50 = pick_users_books(df, 2000, 50)\n",
    "    train_10000_100, test_10000_100 = pick_users_books(df, 10000, 100)\n",
    "    return train_500_20, test_500_20, train_2000_50, test_2000_50, train_10000_100, test_10000_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_500_20, test_500_20, train_2000_50, test_2000_50, train_10000_100, test_10000_100 = get_all_subsets(ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(X_train, X_test):\n",
    "    \n",
    "    # create user and book indices starting from 0\n",
    "    mappings_user = pd.DataFrame({'user_id': sorted(X_train.user_id.unique()), \n",
    "                              'user_idx': range(len(X_train.user_id.unique()))})\n",
    "    mappings_book = pd.DataFrame({'book_id': sorted(X_train.book_id.unique()), \n",
    "                              'book_idx': range(len(X_train.book_id.unique()))})\n",
    "    X_train = pd.merge(X_train, mappings_user, on='user_id')\n",
    "    X_train = pd.merge(X_train, mappings_book, on='book_id')\n",
    "    X_test = pd.merge(X_test, mappings_user, on='user_id')\n",
    "    X_test = pd.merge(X_test, mappings_book, on='book_id')\n",
    "    \n",
    "    # create user-item matrix for training data and find non-zero values\n",
    "    M = np.array(X_train.pivot_table(index = 'user_idx', columns='book_idx', values='rating', fill_value=0))\n",
    "    mask = M != 0\n",
    "    \n",
    "    # use fake data to make test matrix that matches the size of the train matrix\n",
    "    fake_book = pd.DataFrame({'user_id': sorted(X_train.user_id.unique()), 'rating': 0,\n",
    "                          'user_idx': range(len(X_train.user_id.unique())), 'book_id': 'XXX', 'book_idx': 100})\n",
    "    fake_user = pd.DataFrame({'book_id': sorted(X_train.book_id.unique()), 'rating': 0,\n",
    "                          'book_idx': range(len(X_train.book_id.unique())), 'user_id': 'XXX', 'user_idx': 10000000000})\n",
    "    X_test = pd.concat([X_test, fake_book, fake_user])\n",
    "    M_test = X_test.pivot_table(index = 'user_idx', columns='book_idx', values='rating', fill_value=0)\n",
    "    M_test.drop(100, axis=1, inplace=True)\n",
    "    M_test.drop(10000000000, axis=0, inplace=True)\n",
    "    \n",
    "    # subtract off user means\n",
    "    means_list = []\n",
    "    for row in range(M.shape[0]):\n",
    "        n_ratings = len(np.where(M[row,:] != 0)[0])\n",
    "        means_list.append(np.sum(M[row,:]) / n_ratings)\n",
    "    means = np.array(means_list).reshape(-1,1)\n",
    "    M_norm = (M - means) * mask\n",
    "    \n",
    "    return (M_norm, means, M_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update(R, mask, U, V, alpha, E): # performs one iteration of updating U and V matrices\n",
    "    U_new = U + (alpha * np.dot(E, V))\n",
    "    V_new = V + (alpha * np.dot(E.transpose(), U))\n",
    "    return (U_new, V_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_error(R, mask, U, V): \n",
    "    # calculates error matrix - difference between prediction and true rating where true rating exists, 0 otherwise\n",
    "    E = (R - np.dot(U, V.transpose())) * mask\n",
    "    return E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_loss(E): # calculate value of loss function based on error matrix\n",
    "    J = 0.5 * np.sum(np.square(E))\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mat_fact(R, d, alpha):\n",
    "    # initialize U and V\n",
    "    U = np.random.randn(R.shape[0], d)\n",
    "    V = np.random.randn(R.shape[1], d)\n",
    "    \n",
    "    # calculate error and loss\n",
    "    mask = R != 0\n",
    "    E = calc_error(R, mask, U, V)\n",
    "    J_prev = calc_loss(E)\n",
    "    J_ratio = 1\n",
    "    \n",
    "    # while not converged, update U and V and recalculate error and loss\n",
    "    while np.abs(J_ratio) > .00001:\n",
    "        U, V = update(R, mask, U, V, alpha, E)\n",
    "        E = calc_error(R, mask, U, V)\n",
    "        J = calc_loss(E)\n",
    "        J_ratio = (J_prev - J) / J_prev\n",
    "        J_prev = J\n",
    "            \n",
    "    return (U, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_RMSE(M_test, preds): # calculate RMSE using only observed entries\n",
    "    mask_test = M_test != 0\n",
    "    preds_masked = mask_test * preds\n",
    "    rmse = np.sqrt(np.sum(np.sum(np.square(preds_masked - M_test))) / np.sum(np.sum(mask_test)))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid-Search Parameters\n",
    "Use only biggest subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_values = [6, 8, 10, 12, 14, 16, 18, 20]\n",
    "alpha_values = [0.00005, 0.0001, 0.00015, 0.0002, 0.00025, 0.0003]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def overall(data, d, alpha):\n",
    "    k_fold = KFold(n_splits=3)\n",
    "    rmses = []\n",
    "    for train_indices, test_indices in k_fold.split(data):\n",
    "        X_train = data.iloc[train_indices]\n",
    "        X_test = data.iloc[test_indices]\n",
    "        M_norm, means, X_test = preprocess(X_train, X_test)\n",
    "        U, V = mat_fact(M_norm, d, alpha)\n",
    "        preds = np.dot(U, V.transpose()) + means\n",
    "        rmse = calc_RMSE(X_test, preds)\n",
    "        rmses.append(rmse)\n",
    "    return np.mean(rmses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current d value:  6\n",
      "Current alpha value:  5e-05\n",
      "Current alpha value:  0.0001\n",
      "Current alpha value:  0.00015\n",
      "Current alpha value:  0.0002\n",
      "Current alpha value:  0.00025\n",
      "Current alpha value:  0.0003\n",
      "Current d value:  8\n",
      "Current alpha value:  5e-05\n",
      "Current alpha value:  0.0001\n",
      "Current alpha value:  0.00015\n",
      "Current alpha value:  0.0002\n",
      "Current alpha value:  0.00025\n",
      "Current alpha value:  0.0003\n",
      "Current d value:  10\n",
      "Current alpha value:  5e-05\n",
      "Current alpha value:  0.0001\n",
      "Current alpha value:  0.00015\n",
      "Current alpha value:  0.0002\n",
      "Current alpha value:  0.00025\n",
      "Current alpha value:  0.0003\n",
      "Current d value:  12\n",
      "Current alpha value:  5e-05\n",
      "Current alpha value:  0.0001\n",
      "Current alpha value:  0.00015\n",
      "Current alpha value:  0.0002\n",
      "Current alpha value:  0.00025\n",
      "Current alpha value:  0.0003\n",
      "Current d value:  14\n",
      "Current alpha value:  5e-05\n",
      "Current alpha value:  0.0001\n",
      "Current alpha value:  0.00015\n",
      "Current alpha value:  0.0002\n",
      "Current alpha value:  0.00025\n",
      "Current alpha value:  0.0003\n",
      "Current d value:  16\n",
      "Current alpha value:  5e-05\n",
      "Current alpha value:  0.0001\n",
      "Current alpha value:  0.00015\n",
      "Current alpha value:  0.0002\n",
      "Current alpha value:  0.00025\n",
      "Current alpha value:  0.0003\n",
      "Current d value:  18\n",
      "Current alpha value:  5e-05\n",
      "Current alpha value:  0.0001\n",
      "Current alpha value:  0.00015\n",
      "Current alpha value:  0.0002\n",
      "Current alpha value:  0.00025\n",
      "Current alpha value:  0.0003\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-09c413ed79d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;32min\u001b[0m \u001b[0malpha_values\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Current alpha value: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moverall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_10000_100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mgrid_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrmse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-63-4070e95198fa>\u001b[0m in \u001b[0;36moverall\u001b[0;34m(data, d, alpha)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mM_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat_fact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmeans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_RMSE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-78265cf332b4>\u001b[0m in \u001b[0;36mmat_fact\u001b[0;34m(R, d, alpha)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJ_ratio\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m.00001\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mJ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mJ_ratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mJ_prev\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mJ\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mJ_prev\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-5a5c0e5d1adb>\u001b[0m in \u001b[0;36mcalc_error\u001b[0;34m(R, mask, U, V)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "grid_results = {}\n",
    "for d in d_values:\n",
    "    print('Current d value: ', d)\n",
    "    for alpha in alpha_values:\n",
    "        print('Current alpha value: ', alpha)\n",
    "        rmse = overall(train_10000_100, d, alpha)\n",
    "        grid_results[(d, alpha)] = rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters were (6, 5e-05), with average RMSE 0.9587896929775073.\n"
     ]
    }
   ],
   "source": [
    "print('The best parameters were {}, with average RMSE {}.'.format(min(pd.DataFrame(grid_results, index=[0])), \n",
    "                                        grid_results[min(pd.DataFrame(grid_results, index=[0]))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train 3 Subsets to Observe Scalability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_MAE(M_test, preds): # calculate MAE using only observed entries\n",
    "    mask_test = M_test != 0\n",
    "    preds_masked = mask_test * preds\n",
    "    mae = np.sum(np.sum(preds_masked - M_test)) / np.sum(np.sum(mask_test))\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test(X_train, X_test):\n",
    "    M_norm, means, X_test = preprocess(X_train, X_test)\n",
    "    start_time = time.time()\n",
    "    U, V = mat_fact(M_norm, 6, 5e-05)\n",
    "    end_time = time.time()\n",
    "    preds = np.dot(U, V.transpose()) + means\n",
    "    rmse = calc_RMSE(X_test, preds)\n",
    "    mae = calc_MAE(X_test, preds)\n",
    "    return (end_time - start_time, rmse, mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subsets = [(train_500_20, test_500_20, 500, 20), (train_2000_50, test_2000_50, 2000, 50), \n",
    "           (train_10000_100, test_10000_100, 10000, 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a subset of 500 users and 20 items, training took place in 0.16950702667236328 seconds and gave an RMSE of 0.9464489398289763 and an MAE of -0.051829514481699826.\n",
      "With a subset of 2000 users and 50 items, training took place in 0.34920597076416016 seconds and gave an RMSE of 0.9582427763921908 and an MAE of 0.008984004491459337.\n",
      "With a subset of 10000 users and 100 items, training took place in 1.7402470111846924 seconds and gave an RMSE of 0.9492886904402659 and an MAE of 0.003407143513349153.\n"
     ]
    }
   ],
   "source": [
    "for (X_train, X_test, n_users, n_items) in subsets:\n",
    "    elapsed_time, rmse, mae = train_test(X_train, X_test)\n",
    "    print('With a subset of {} users and {} items, training took place in {} seconds and gave an RMSE of {} and an MAE of {}.'.format(n_users, n_items, elapsed_time, rmse, mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3k]",
   "language": "python",
   "name": "conda-env-py3k-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
