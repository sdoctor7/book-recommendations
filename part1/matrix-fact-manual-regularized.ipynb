{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import time\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('../../ratings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Subsets of Data for Part I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pick_users_books(df, num_users, num_books):\n",
    "    user_counts = pd.DataFrame(df.user_id.value_counts()).sort_values('user_id', ascending=False)\n",
    "    top_10K_users = list(user_counts[0:num_users].index)\n",
    "    user_filtered_df = df[df.user_id.isin(top_10K_users)]\n",
    "    filtered_book_counts = pd.DataFrame(user_filtered_df.book_id.value_counts()).sort_values('book_id', \n",
    "                                                                                             ascending = False)\n",
    "    top_100_filtered_books = list(filtered_book_counts[0:num_books].index)\n",
    "    filtered_df = user_filtered_df[user_filtered_df.book_id.isin(top_100_filtered_books)]\n",
    "    train, test = train_test_split(filtered_df, test_size = 0.2, random_state=42)\n",
    "    return train, test\n",
    "    \n",
    "def get_all_subsets(df):\n",
    "    train_500_20, test_500_20 = pick_users_books(df, 500, 20)\n",
    "    train_1000_35, test_1000_35 = pick_users_books(df, 1000, 35)\n",
    "    train_2000_50, test_2000_50 = pick_users_books(df, 2000, 50)\n",
    "    train_5000_70, test_5000_70 = pick_users_books(df, 5000, 70)\n",
    "    train_7500_85, test_7500_85 = pick_users_books(df, 7500, 85)\n",
    "    train_10000_100, test_10000_100 = pick_users_books(df, 10000, 100)\n",
    "    return train_500_20, test_500_20, train_1000_35, test_1000_35, train_2000_50, test_2000_50, \\\n",
    "        train_5000_70, test_5000_70, train_7500_85, test_7500_85, train_10000_100, test_10000_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_500_20, test_500_20, train_1000_35, test_1000_35, train_2000_50, test_2000_50, train_5000_70, test_5000_70, \\\n",
    "    train_7500_85, test_7500_85, train_10000_100, test_10000_100 = get_all_subsets(ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(X_train, X_test):\n",
    "    \n",
    "    # create user and book indices starting from 0\n",
    "    mappings_user = pd.DataFrame({'user_id': sorted(X_train.user_id.unique()), \n",
    "                              'user_idx': range(len(X_train.user_id.unique()))})\n",
    "    mappings_book = pd.DataFrame({'book_id': sorted(X_train.book_id.unique()), \n",
    "                              'book_idx': range(len(X_train.book_id.unique()))})\n",
    "    X_train = pd.merge(X_train, mappings_user, on='user_id')\n",
    "    X_train = pd.merge(X_train, mappings_book, on='book_id')\n",
    "    X_test = pd.merge(X_test, mappings_user, on='user_id')\n",
    "    X_test = pd.merge(X_test, mappings_book, on='book_id')\n",
    "    \n",
    "    # create user-item matrix for training data and find non-zero values\n",
    "    M = np.array(X_train.pivot_table(index = 'user_idx', columns='book_idx', values='rating', fill_value=0))\n",
    "    mask = M != 0\n",
    "    \n",
    "    # use fake data to make test matrix that matches the size of the train matrix\n",
    "    fake_book = pd.DataFrame({'user_id': sorted(X_train.user_id.unique()), 'rating': 0,\n",
    "                          'user_idx': range(len(X_train.user_id.unique())), 'book_id': 'XXX', 'book_idx': 100})\n",
    "    fake_user = pd.DataFrame({'book_id': sorted(X_train.book_id.unique()), 'rating': 0,\n",
    "                          'book_idx': range(len(X_train.book_id.unique())), 'user_id': 'XXX', 'user_idx': 10000000000})\n",
    "    X_test = pd.concat([X_test, fake_book, fake_user])\n",
    "    M_test = X_test.pivot_table(index = 'user_idx', columns='book_idx', values='rating', fill_value=0)\n",
    "    M_test.drop(100, axis=1, inplace=True)\n",
    "    M_test.drop(10000000000, axis=0, inplace=True)\n",
    "    \n",
    "    # subtract off user means\n",
    "    means_list = []\n",
    "    for row in range(M.shape[0]):\n",
    "        n_ratings = len(np.where(M[row,:] != 0)[0])\n",
    "        means_list.append(np.sum(M[row,:]) / n_ratings)\n",
    "    means = np.array(means_list).reshape(-1,1)\n",
    "    M_norm = (M - means) * mask\n",
    "    \n",
    "    return (M_norm, means, np.array(M_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update(R, mask, U, V, alpha, E, lamb): # performs one iteration of updating U and V matrices\n",
    "    U_new = (U * (1 - (alpha * lamb))) + (alpha * np.dot(E, V))\n",
    "    V_new = (V * (1 - (alpha * lamb))) + (alpha * np.dot(E.transpose(), U))\n",
    "    return (U_new, V_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_error(R, mask, U, V): \n",
    "    # calculates error matrix - difference between prediction and true rating where true rating exists, 0 otherwise\n",
    "    E = (R - np.dot(U, V.transpose())) * mask\n",
    "    return E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_loss(E, U, V, lamb): # calculate value of loss function based on error matrix\n",
    "    J = (0.5 * np.sum(np.square(E))) + ((lamb/2) * np.sum(np.square(U))) + ((lamb/2) * np.sum(np.square(V)))\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mat_fact(R, d, alpha, lamb):\n",
    "    # initialize U and V\n",
    "    U = np.random.randn(R.shape[0], d)\n",
    "    V = np.random.randn(R.shape[1], d)\n",
    "    \n",
    "    # calculate error and loss\n",
    "    mask = R != 0\n",
    "    E = calc_error(R, mask, U, V)\n",
    "    J_prev = calc_loss(E, U, V, lamb)\n",
    "    J_ratio = 1\n",
    "    \n",
    "    # while not converged, update U and V and recalculate error and loss\n",
    "    count = 0\n",
    "    while np.abs(J_ratio) > .00001:\n",
    "        if count > 1000 and J_prev > 10000:\n",
    "            print('Did not converge!')\n",
    "            return (U, V)\n",
    "        else:\n",
    "            U, V = update(R, mask, U, V, alpha, E, lamb)\n",
    "            E = calc_error(R, mask, U, V)\n",
    "            J = calc_loss(E, U, V, lamb)\n",
    "            J_ratio = (J_prev - J) / J_prev\n",
    "            J_prev = J\n",
    "            count += 1\n",
    "            \n",
    "    return (U, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_RMSE(M_test, preds): # calculate RMSE using only observed entries\n",
    "    mask_test = M_test != 0\n",
    "    preds_masked = mask_test * preds\n",
    "    rmse = np.sqrt(np.sum(np.sum(np.square(preds_masked - M_test))) / np.sum(np.sum(mask_test)))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid-Search Parameters\n",
    "Use only biggest subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# d_values = [5, 10, 15]\n",
    "# alpha_values = [0.00005, 0.0001, 0.00015, 0.0002]\n",
    "# lamb_values = [0.00001, 0.0001, 0.001, 0.01, 0.1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def overall(data, d, alpha, lamb):\n",
    "#     k_fold = KFold(n_splits=3)\n",
    "#     rmses = []\n",
    "#     for train_indices, test_indices in k_fold.split(data):\n",
    "#         X_train = data.iloc[train_indices]\n",
    "#         X_test = data.iloc[test_indices]\n",
    "#         M_norm, means, X_test = preprocess(X_train, X_test)\n",
    "#         U, V = mat_fact(M_norm, d, alpha, lamb)\n",
    "#         preds = np.dot(U, V.transpose()) + means\n",
    "#         rmse = calc_RMSE(X_test, preds)\n",
    "#         rmses.append(rmse)\n",
    "#     return np.mean(rmses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current d value:  5\n",
      "Current alpha value:  5e-05\n",
      "Current lambda value:  1e-05\n",
      "Current lambda value:  0.0001\n",
      "Current lambda value:  0.001\n",
      "Current lambda value:  0.01\n",
      "Current lambda value:  0.1\n",
      "Current lambda value:  1\n",
      "Did not converge!\n",
      "Did not converge!\n",
      "Did not converge!\n",
      "Current alpha value:  0.0001\n",
      "Current lambda value:  1e-05\n",
      "Current lambda value:  0.0001\n",
      "Current lambda value:  0.001\n",
      "Current lambda value:  0.01\n",
      "Current lambda value:  0.1\n",
      "Current lambda value:  1\n",
      "Did not converge!\n",
      "Did not converge!\n",
      "Did not converge!\n",
      "Current alpha value:  0.00015\n",
      "Current lambda value:  1e-05\n",
      "Current lambda value:  0.0001\n",
      "Current lambda value:  0.001\n",
      "Current lambda value:  0.01\n",
      "Current lambda value:  0.1\n",
      "Current lambda value:  1\n",
      "Did not converge!\n",
      "Did not converge!\n",
      "Did not converge!\n",
      "Current alpha value:  0.0002\n",
      "Current lambda value:  1e-05\n",
      "Current lambda value:  0.0001\n",
      "Current lambda value:  0.001\n",
      "Current lambda value:  0.01\n",
      "Current lambda value:  0.1\n",
      "Current lambda value:  1\n",
      "Did not converge!\n",
      "Did not converge!\n",
      "Did not converge!\n",
      "Current d value:  10\n",
      "Current alpha value:  5e-05\n",
      "Current lambda value:  1e-05\n",
      "Current lambda value:  0.0001\n",
      "Current lambda value:  0.001\n",
      "Current lambda value:  0.01\n",
      "Current lambda value:  0.1\n",
      "Current lambda value:  1\n",
      "Did not converge!\n",
      "Did not converge!\n",
      "Did not converge!\n",
      "Current alpha value:  0.0001\n",
      "Current lambda value:  1e-05\n",
      "Current lambda value:  0.0001\n",
      "Current lambda value:  0.001\n",
      "Current lambda value:  0.01\n",
      "Current lambda value:  0.1\n",
      "Current lambda value:  1\n",
      "Did not converge!\n",
      "Did not converge!\n",
      "Did not converge!\n",
      "Current alpha value:  0.00015\n",
      "Current lambda value:  1e-05\n",
      "Current lambda value:  0.0001\n",
      "Current lambda value:  0.001\n",
      "Current lambda value:  0.01\n",
      "Current lambda value:  0.1\n",
      "Current lambda value:  1\n",
      "Did not converge!\n",
      "Did not converge!\n",
      "Did not converge!\n",
      "Current alpha value:  0.0002\n",
      "Current lambda value:  1e-05\n",
      "Current lambda value:  0.0001\n",
      "Current lambda value:  0.001\n",
      "Current lambda value:  0.01\n",
      "Current lambda value:  0.1\n",
      "Current lambda value:  1\n",
      "Did not converge!\n",
      "Did not converge!\n",
      "Did not converge!\n",
      "Current d value:  15\n",
      "Current alpha value:  5e-05\n",
      "Current lambda value:  1e-05\n",
      "Current lambda value:  0.0001\n",
      "Current lambda value:  0.001\n",
      "Current lambda value:  0.01\n",
      "Current lambda value:  0.1\n",
      "Current lambda value:  1\n",
      "Did not converge!\n",
      "Did not converge!\n",
      "Did not converge!\n",
      "Current alpha value:  0.0001\n",
      "Current lambda value:  1e-05\n",
      "Current lambda value:  0.0001\n",
      "Current lambda value:  0.001\n",
      "Current lambda value:  0.01\n",
      "Current lambda value:  0.1\n",
      "Current lambda value:  1\n",
      "Did not converge!\n",
      "Did not converge!\n",
      "Did not converge!\n",
      "Current alpha value:  0.00015\n",
      "Current lambda value:  1e-05\n",
      "Current lambda value:  0.0001\n",
      "Current lambda value:  0.001\n",
      "Current lambda value:  0.01\n",
      "Current lambda value:  0.1\n",
      "Current lambda value:  1\n",
      "Did not converge!\n",
      "Did not converge!\n",
      "Did not converge!\n",
      "Current alpha value:  0.0002\n",
      "Current lambda value:  1e-05\n",
      "Current lambda value:  0.0001\n",
      "Current lambda value:  0.001\n",
      "Current lambda value:  0.01\n",
      "Current lambda value:  0.1\n",
      "Current lambda value:  1\n",
      "Did not converge!\n",
      "Did not converge!\n",
      "Did not converge!\n"
     ]
    }
   ],
   "source": [
    "# grid_results_all = []\n",
    "# for d in d_values:\n",
    "#     print('Current d value: ', d)\n",
    "#     for alpha in alpha_values:\n",
    "#         print('Current alpha value: ', alpha)\n",
    "#         for lamb in lamb_values:\n",
    "#             print('Current lambda value: ', lamb)\n",
    "#             grid_results = {}\n",
    "#             rmse = overall(train_10000_100, d, alpha, lamb)\n",
    "#             grid_results['d'] = d\n",
    "#             grid_results['alpha'] = alpha\n",
    "#             grid_results['lambda'] = lamb\n",
    "#             grid_results['rmse'] = rmse\n",
    "#             grid_results_all.append(grid_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# grid_df = pd.DataFrame(grid_results_all)\n",
    "# grid_df\n",
    "# grid_df.to_pickle('grid_results.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alpha     0.000100\n",
       "d         5.000000\n",
       "lambda    0.001000\n",
       "rmse      0.958122\n",
       "Name: 8, dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grid_df.iloc[grid_df['rmse'].idxmin()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters were d = 5.0, alpha = 0.0001, and lambda = 0.001, with an average RMSE of 0.9581215576515847.\n"
     ]
    }
   ],
   "source": [
    "# min_values = grid_df.iloc[grid_df['rmse'].idxmin()]\n",
    "# print('The best parameters were d = {}, alpha = {}, and lambda = {}, with an average RMSE of {}.'\n",
    "#       .format(min_values['d'], min_values['alpha'], min_values['lambda'], min_values['rmse']))\n",
    "\n",
    "# # RESULT: The best parameters were d = 5.0, alpha = 0.0001, and lambda = 0.001, with an average RMSE of 0.9581215576515847."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train 6 Subsets to Observe Scalability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_MAE(M_test, preds): # calculate MAE using only observed entries\n",
    "    mask_test = M_test != 0\n",
    "    preds_masked = mask_test * preds\n",
    "    mae = np.sum(np.sum(np.abs(preds_masked - M_test))) / np.sum(np.sum(mask_test))\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_spearman(M_test, preds): # calculate spearman coefficient using only observed entries\n",
    "    spearmans = []\n",
    "    for i in range(len(M_test)):\n",
    "        mask = M_test[i,:] != 0\n",
    "        if sum(mask) > 1: # can't calculate if there's only one item rated\n",
    "            M_test_mask = M_test[i, mask]\n",
    "            preds_mask = preds[i, mask]\n",
    "            spearman = spearmanr(M_test_mask, preds_mask)[0]\n",
    "            if np.isnan(spearman) == False: # spearman is NaN if all true ratings are the same! exclude these\n",
    "                spearmans.append(spearman)\n",
    "    return np.mean(spearmans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test(X_train, X_test):\n",
    "    M_norm, means, X_test = preprocess(X_train, X_test)\n",
    "    start_train = time.time()\n",
    "    U, V = mat_fact(M_norm, 5, 0.0001, 0.001)\n",
    "    end_train = time.time()\n",
    "    start_pred = time.time()\n",
    "    preds = np.dot(U, V.transpose()) + means\n",
    "    end_pred = time.time()\n",
    "    rmse = calc_RMSE(X_test, preds)\n",
    "    mae = calc_MAE(X_test, preds)\n",
    "    spearman = calc_spearman(X_test, preds)\n",
    "    train_time = end_train - start_train\n",
    "    pred_time = end_pred - start_pred\n",
    "    return (train_time, pred_time, rmse, mae, spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subsets = [(train_500_20, test_500_20, 500, 20), (train_1000_35, test_1000_35, 1000, 35), \n",
    "           (train_2000_50, test_2000_50, 2000, 50), (train_5000_70, test_5000_70, 5000, 70),\n",
    "           (train_7500_85, test_7500_85, 7500, 85), (train_10000_100, test_10000_100, 10000, 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scalability_all = []\n",
    "for (X_train, X_test, n_users, n_items) in subsets:\n",
    "    scalability = {}\n",
    "    train_time, pred_time, rmse, mae, spearman = train_test(X_train, X_test)\n",
    "    scalability['Number of Users'] = n_users\n",
    "    scalability['Number of Items'] = n_items\n",
    "    scalability['Time to Train'] = train_time\n",
    "    scalability['Time to Predict'] = pred_time\n",
    "    scalability['RMSE'] = rmse\n",
    "    scalability['MAE'] = mae\n",
    "    scalability['Spearman'] = spearman\n",
    "    scalability_all.append(scalability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>Number of Items</th>\n",
       "      <th>Number of Users</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Spearman</th>\n",
       "      <th>Time to Predict</th>\n",
       "      <th>Time to Train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.722292</td>\n",
       "      <td>20</td>\n",
       "      <td>500</td>\n",
       "      <td>0.934416</td>\n",
       "      <td>0.002052</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.087984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.744592</td>\n",
       "      <td>35</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.969022</td>\n",
       "      <td>-0.022090</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.128904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.739621</td>\n",
       "      <td>50</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.956829</td>\n",
       "      <td>0.024255</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>0.207256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.722454</td>\n",
       "      <td>70</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.931651</td>\n",
       "      <td>0.006256</td>\n",
       "      <td>0.002735</td>\n",
       "      <td>0.466233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.736573</td>\n",
       "      <td>85</td>\n",
       "      <td>7500</td>\n",
       "      <td>0.943755</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.004573</td>\n",
       "      <td>0.674893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.739497</td>\n",
       "      <td>100</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.949419</td>\n",
       "      <td>0.002610</td>\n",
       "      <td>0.008565</td>\n",
       "      <td>1.053142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MAE  Number of Items  Number of Users      RMSE  Spearman  \\\n",
       "0  0.722292               20              500  0.934416  0.002052   \n",
       "1  0.744592               35             1000  0.969022 -0.022090   \n",
       "2  0.739621               50             2000  0.956829  0.024255   \n",
       "3  0.722454               70             5000  0.931651  0.006256   \n",
       "4  0.736573               85             7500  0.943755  0.000212   \n",
       "5  0.739497              100            10000  0.949419  0.002610   \n",
       "\n",
       "   Time to Predict  Time to Train  \n",
       "0         0.000043       0.087984  \n",
       "1         0.000178       0.128904  \n",
       "2         0.000336       0.207256  \n",
       "3         0.002735       0.466233  \n",
       "4         0.004573       0.674893  \n",
       "5         0.008565       1.053142  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scalability_all)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3k]",
   "language": "python",
   "name": "conda-env-py3k-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
