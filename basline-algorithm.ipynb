{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import math modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import surprise modules\n",
    "from surprise.prediction_algorithms.random_pred import NormalPredictor\n",
    "from surprise.prediction_algorithms.baseline_only import BaselineOnly\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import evaluate, print_perf\n",
    "from surprise import GridSearch\n",
    "from surprise import accuracy\n",
    "\n",
    "#Graphing\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Setup functions to split data for testing and training\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def pick_users_books(df, num_users, num_books):\n",
    "    #Get the top num_users most prolific users\n",
    "    user_counts = pd.DataFrame(df.user_id.value_counts()).sort_values('user_id', ascending=False)\n",
    "    top_10K_users = list(user_counts[0:num_users].index)\n",
    "    user_filtered_df = df[df.user_id.isin(top_10K_users)]\n",
    "    #Get the top num_books most reviewed books by the selected users\n",
    "    filtered_book_counts = pd.DataFrame(user_filtered_df.book_id.value_counts()).sort_values('book_id', ascending = False)\n",
    "    top_100_filtered_books = list(filtered_book_counts[0:num_books].index)\n",
    "    #Generate new filtered dataframe\n",
    "    filtered_df = user_filtered_df[user_filtered_df.book_id.isin(top_100_filtered_books)]\n",
    "    print(\"New dataframe has {} users, {} items, and a sparsity of {}\".format(len(filtered_df.user_id.unique()),len(filtered_df.book_id.unique()),len(filtered_df)/(len(filtered_df.user_id.unique())*len(filtered_df.book_id.unique()))))\n",
    "    #Split dataframe into training and test sets\n",
    "    train, test = train_test_split(filtered_df, test_size = 0.2, random_state=42)\n",
    "    return train, test\n",
    "\n",
    "def get_all_subsets(df):\n",
    "    #Generate different subsets for scaling purposes\n",
    "    train_500_20, test_500_20 = pick_users_books(df, 500, 20)\n",
    "    train_2000_50, test_2000_50 = pick_users_books(df, 2000, 50)\n",
    "    train_10000_100, test_10000_100 = pick_users_books(df, 10000, 100)\n",
    "\n",
    "    return train_500_20, test_500_20, train_2000_50, test_2000_50, train_10000_100, test_10000_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set up functions to nicely display gridsearch data in a table\n",
    "#Need to do results_df = pd.DataFrame.from_dict(grid_search.cv_results)\n",
    "\n",
    "#Function for alternating least squares\n",
    "def convert_grid_results_als(df):\n",
    "\n",
    "    my_dict = df.to_dict('list')\n",
    "    method = []\n",
    "    reg_i = []\n",
    "    reg_u = []\n",
    "    n_epochs = []\n",
    "    \n",
    "    for x in range(len(my_dict['bsl_options'])):\n",
    "        y = my_dict['bsl_options'][x]\n",
    "        method.append(y['method'])\n",
    "        reg_i.append(y['reg_i'])    \n",
    "        reg_u.append(y['reg_u'])\n",
    "        n_epochs.append(y['n_epochs'])\n",
    "\n",
    "    del my_dict['params']\n",
    "    del my_dict['scores']\n",
    "    del my_dict['bsl_options']\n",
    "\n",
    "    my_dict['method'] = method\n",
    "    my_dict['reg_i'] = reg_i\n",
    "    my_dict['reg_u'] = reg_u\n",
    "    my_dict['n_epochs'] = n_epochs\n",
    "    my_df = pd.DataFrame.from_dict(my_dict).sort_values('RMSE')\n",
    "\n",
    "    return my_df\n",
    "\n",
    "#Function for gradient descent\n",
    "def convert_grid_results_sgd(df):\n",
    "\n",
    "    my_dict = df.to_dict('list')\n",
    "    method = []\n",
    "    reg = []\n",
    "    learning_rate = [] \n",
    "    n_epochs = []\n",
    "\n",
    "    for x in range(len(my_dict['bsl_options'])):\n",
    "        y = my_dict['bsl_options'][x]\n",
    "        method.append(y['method'])\n",
    "        reg.append(y['reg'])        \n",
    "        learning_rate.append(y['learning_rate'])\n",
    "        n_epochs.append(y['n_epochs'])\n",
    "\n",
    "    del my_dict['params']\n",
    "    del my_dict['scores']\n",
    "    del my_dict['bsl_options']\n",
    "\n",
    "    my_dict['method'] = method\n",
    "    my_dict['reg'] = reg    \n",
    "    my_dict['learning_rate'] = learning_rate\n",
    "    my_dict['n_epochs'] = n_epochs\n",
    "    my_df = pd.DataFrame.from_dict(my_dict).sort_values('RMSE')\n",
    "\n",
    "    return my_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load ratings data\n",
    "ratings = pd.read_csv('../ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New dataframe has 487 users, 20 items, and a sparsity of 0.44260780287474333\n",
      "New dataframe has 1981 users, 50 items, and a sparsity of 0.3745583038869258\n",
      "New dataframe has 9980 users, 100 items, and a sparsity of 0.2719659318637275\n",
      "New dataframe has 988 users, 50 items, and a sparsity of 0.3857085020242915\n",
      "New dataframe has 4985 users, 75 items, and a sparsity of 0.317753259779338\n",
      "New dataframe has 2970 users, 50 items, and a sparsity of 0.3695084175084175\n",
      "New dataframe has 7488 users, 100 items, and a sparsity of 0.28153044871794874\n"
     ]
    }
   ],
   "source": [
    "#Split data into trainint and test sets of different sizes\n",
    "train_500_20, test_500_20, train_2000_50, test_2000_50, train_10000_100, test_10000_100 = get_all_subsets(ratings)\n",
    "\n",
    "#More datasets\n",
    "tr1, t1 = pick_users_books(ratings, 1000, 50)\n",
    "all_1000_50 = tr1.append(t1)\n",
    "tr2, t2 = pick_users_books(ratings, 5000, 75)\n",
    "all_5000_75 = tr2.append(t2)\n",
    "tr3, t3 = pick_users_books(ratings, 3000, 50)\n",
    "all_3000_50 = tr3.append(t3)\n",
    "tr4, t4 = pick_users_books(ratings, 7500, 100)\n",
    "all_7500_100 = tr4.append(t4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm NormalPredictor.\n",
      "\n",
      "------------\n",
      "Fold 1\n",
      "RMSE: 1.3519\n",
      "MAE:  1.0657\n",
      "------------\n",
      "Fold 2\n",
      "RMSE: 1.3599\n",
      "MAE:  1.0734\n",
      "------------\n",
      "Fold 3\n",
      "RMSE: 1.3569\n",
      "MAE:  1.0686\n",
      "------------\n",
      "------------\n",
      "Mean RMSE: 1.3562\n",
      "Mean MAE : 1.0693\n",
      "------------\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "#Run the Normal predictor - no gridsearch needed\n",
    "algo = NormalPredictor()\n",
    "reader = Reader(rating_scale=(1,5))\n",
    "train = Dataset.load_from_df(train_10000_100, reader)\n",
    "test = Dataset.load_from_df(test_10000_100, reader)\n",
    "train.split(n_folds=3)\n",
    "perf = evaluate(algo, train, measures=['RMSE', 'MAE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'bsl_options': {'n_epochs': 10, 'method': 'sgd', 'learning_rate': 0.005, 'reg': 0.02}}, {'bsl_options': {'n_epochs': 10, 'method': 'sgd', 'learning_rate': 0.005, 'reg': 0.01}}, {'bsl_options': {'n_epochs': 10, 'method': 'sgd', 'learning_rate': 0.005, 'reg': 0.05}}, {'bsl_options': {'n_epochs': 10, 'method': 'sgd', 'learning_rate': 0.001, 'reg': 0.02}}, {'bsl_options': {'n_epochs': 10, 'method': 'sgd', 'learning_rate': 0.001, 'reg': 0.01}}, {'bsl_options': {'n_epochs': 10, 'method': 'sgd', 'learning_rate': 0.001, 'reg': 0.05}}, {'bsl_options': {'n_epochs': 10, 'method': 'sgd', 'learning_rate': 0.01, 'reg': 0.02}}, {'bsl_options': {'n_epochs': 10, 'method': 'sgd', 'learning_rate': 0.01, 'reg': 0.01}}, {'bsl_options': {'n_epochs': 10, 'method': 'sgd', 'learning_rate': 0.01, 'reg': 0.05}}, {'bsl_options': {'n_epochs': 20, 'method': 'sgd', 'learning_rate': 0.005, 'reg': 0.02}}, {'bsl_options': {'n_epochs': 20, 'method': 'sgd', 'learning_rate': 0.005, 'reg': 0.01}}, {'bsl_options': {'n_epochs': 20, 'method': 'sgd', 'learning_rate': 0.005, 'reg': 0.05}}, {'bsl_options': {'n_epochs': 20, 'method': 'sgd', 'learning_rate': 0.001, 'reg': 0.02}}, {'bsl_options': {'n_epochs': 20, 'method': 'sgd', 'learning_rate': 0.001, 'reg': 0.01}}, {'bsl_options': {'n_epochs': 20, 'method': 'sgd', 'learning_rate': 0.001, 'reg': 0.05}}, {'bsl_options': {'n_epochs': 20, 'method': 'sgd', 'learning_rate': 0.01, 'reg': 0.02}}, {'bsl_options': {'n_epochs': 20, 'method': 'sgd', 'learning_rate': 0.01, 'reg': 0.01}}, {'bsl_options': {'n_epochs': 20, 'method': 'sgd', 'learning_rate': 0.01, 'reg': 0.05}}, {'bsl_options': {'n_epochs': 40, 'method': 'sgd', 'learning_rate': 0.005, 'reg': 0.02}}, {'bsl_options': {'n_epochs': 40, 'method': 'sgd', 'learning_rate': 0.005, 'reg': 0.01}}, {'bsl_options': {'n_epochs': 40, 'method': 'sgd', 'learning_rate': 0.005, 'reg': 0.05}}, {'bsl_options': {'n_epochs': 40, 'method': 'sgd', 'learning_rate': 0.001, 'reg': 0.02}}, {'bsl_options': {'n_epochs': 40, 'method': 'sgd', 'learning_rate': 0.001, 'reg': 0.01}}, {'bsl_options': {'n_epochs': 40, 'method': 'sgd', 'learning_rate': 0.001, 'reg': 0.05}}, {'bsl_options': {'n_epochs': 40, 'method': 'sgd', 'learning_rate': 0.01, 'reg': 0.02}}, {'bsl_options': {'n_epochs': 40, 'method': 'sgd', 'learning_rate': 0.01, 'reg': 0.01}}, {'bsl_options': {'n_epochs': 40, 'method': 'sgd', 'learning_rate': 0.01, 'reg': 0.05}}]\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>method</th>\n",
       "      <th>n_epochs</th>\n",
       "      <th>reg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.896817</td>\n",
       "      <td>0.005</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.896881</td>\n",
       "      <td>0.005</td>\n",
       "      <td>sgd</td>\n",
       "      <td>40</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.896881</td>\n",
       "      <td>0.005</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.897163</td>\n",
       "      <td>0.005</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.897200</td>\n",
       "      <td>0.005</td>\n",
       "      <td>sgd</td>\n",
       "      <td>40</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.897356</td>\n",
       "      <td>0.005</td>\n",
       "      <td>sgd</td>\n",
       "      <td>40</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.898463</td>\n",
       "      <td>0.010</td>\n",
       "      <td>sgd</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.898544</td>\n",
       "      <td>0.010</td>\n",
       "      <td>sgd</td>\n",
       "      <td>10</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.898547</td>\n",
       "      <td>0.010</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.898816</td>\n",
       "      <td>0.010</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.898871</td>\n",
       "      <td>0.010</td>\n",
       "      <td>sgd</td>\n",
       "      <td>10</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.898954</td>\n",
       "      <td>0.010</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.900135</td>\n",
       "      <td>0.010</td>\n",
       "      <td>sgd</td>\n",
       "      <td>40</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.900835</td>\n",
       "      <td>0.010</td>\n",
       "      <td>sgd</td>\n",
       "      <td>40</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.901135</td>\n",
       "      <td>0.010</td>\n",
       "      <td>sgd</td>\n",
       "      <td>40</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.905613</td>\n",
       "      <td>0.005</td>\n",
       "      <td>sgd</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.905773</td>\n",
       "      <td>0.005</td>\n",
       "      <td>sgd</td>\n",
       "      <td>10</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.906310</td>\n",
       "      <td>0.005</td>\n",
       "      <td>sgd</td>\n",
       "      <td>10</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.909848</td>\n",
       "      <td>0.001</td>\n",
       "      <td>sgd</td>\n",
       "      <td>40</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.909977</td>\n",
       "      <td>0.001</td>\n",
       "      <td>sgd</td>\n",
       "      <td>40</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.910420</td>\n",
       "      <td>0.001</td>\n",
       "      <td>sgd</td>\n",
       "      <td>40</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.929717</td>\n",
       "      <td>0.001</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.929797</td>\n",
       "      <td>0.001</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.930089</td>\n",
       "      <td>0.001</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.947758</td>\n",
       "      <td>0.001</td>\n",
       "      <td>sgd</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.947798</td>\n",
       "      <td>0.001</td>\n",
       "      <td>sgd</td>\n",
       "      <td>10</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.947970</td>\n",
       "      <td>0.001</td>\n",
       "      <td>sgd</td>\n",
       "      <td>10</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        RMSE  learning_rate method  n_epochs   reg\n",
       "10  0.896817          0.005    sgd        20  0.01\n",
       "20  0.896881          0.005    sgd        40  0.05\n",
       "9   0.896881          0.005    sgd        20  0.02\n",
       "11  0.897163          0.005    sgd        20  0.05\n",
       "18  0.897200          0.005    sgd        40  0.02\n",
       "19  0.897356          0.005    sgd        40  0.01\n",
       "7   0.898463          0.010    sgd        10  0.01\n",
       "6   0.898544          0.010    sgd        10  0.02\n",
       "17  0.898547          0.010    sgd        20  0.05\n",
       "15  0.898816          0.010    sgd        20  0.02\n",
       "8   0.898871          0.010    sgd        10  0.05\n",
       "16  0.898954          0.010    sgd        20  0.01\n",
       "26  0.900135          0.010    sgd        40  0.05\n",
       "24  0.900835          0.010    sgd        40  0.02\n",
       "25  0.901135          0.010    sgd        40  0.01\n",
       "1   0.905613          0.005    sgd        10  0.01\n",
       "0   0.905773          0.005    sgd        10  0.02\n",
       "2   0.906310          0.005    sgd        10  0.05\n",
       "22  0.909848          0.001    sgd        40  0.01\n",
       "21  0.909977          0.001    sgd        40  0.02\n",
       "23  0.910420          0.001    sgd        40  0.05\n",
       "13  0.929717          0.001    sgd        20  0.01\n",
       "12  0.929797          0.001    sgd        20  0.02\n",
       "14  0.930089          0.001    sgd        20  0.05\n",
       "4   0.947758          0.001    sgd        10  0.01\n",
       "3   0.947798          0.001    sgd        10  0.02\n",
       "5   0.947970          0.001    sgd        10  0.05"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Grid search for baseline - gradient descent\n",
    "param_grid = {'bsl_options':{'method': ['sgd'], 'reg':[.02,.01,.05], 'learning_rate':[.005,.001, .01], 'n_epochs':[10,20,40]}}\n",
    "gridsearch = GridSearch(BaselineOnly, param_grid, measures=['RMSE', 'MAE'], verbose=0)\n",
    "reader = Reader(rating_scale=(1,5))\n",
    "train = Dataset.load_from_df(train_10000_100, reader)\n",
    "test = Dataset.load_from_df(test_10000_100, reader)\n",
    "train.split(n_folds=3)\n",
    "gridsearch.evaluate(train)\n",
    "convert_grid_results_sgd(pd.DataFrame.from_dict(gridsearch.cv_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'bsl_options': {'reg_i': 5, 'method': 'als', 'reg_u': 10, 'n_epochs': 5}}, {'bsl_options': {'reg_i': 5, 'method': 'als', 'reg_u': 10, 'n_epochs': 10}}, {'bsl_options': {'reg_i': 5, 'method': 'als', 'reg_u': 10, 'n_epochs': 20}}, {'bsl_options': {'reg_i': 5, 'method': 'als', 'reg_u': 15, 'n_epochs': 5}}, {'bsl_options': {'reg_i': 5, 'method': 'als', 'reg_u': 15, 'n_epochs': 10}}, {'bsl_options': {'reg_i': 5, 'method': 'als', 'reg_u': 15, 'n_epochs': 20}}, {'bsl_options': {'reg_i': 5, 'method': 'als', 'reg_u': 20, 'n_epochs': 5}}, {'bsl_options': {'reg_i': 5, 'method': 'als', 'reg_u': 20, 'n_epochs': 10}}, {'bsl_options': {'reg_i': 5, 'method': 'als', 'reg_u': 20, 'n_epochs': 20}}, {'bsl_options': {'reg_i': 10, 'method': 'als', 'reg_u': 10, 'n_epochs': 5}}, {'bsl_options': {'reg_i': 10, 'method': 'als', 'reg_u': 10, 'n_epochs': 10}}, {'bsl_options': {'reg_i': 10, 'method': 'als', 'reg_u': 10, 'n_epochs': 20}}, {'bsl_options': {'reg_i': 10, 'method': 'als', 'reg_u': 15, 'n_epochs': 5}}, {'bsl_options': {'reg_i': 10, 'method': 'als', 'reg_u': 15, 'n_epochs': 10}}, {'bsl_options': {'reg_i': 10, 'method': 'als', 'reg_u': 15, 'n_epochs': 20}}, {'bsl_options': {'reg_i': 10, 'method': 'als', 'reg_u': 20, 'n_epochs': 5}}, {'bsl_options': {'reg_i': 10, 'method': 'als', 'reg_u': 20, 'n_epochs': 10}}, {'bsl_options': {'reg_i': 10, 'method': 'als', 'reg_u': 20, 'n_epochs': 20}}, {'bsl_options': {'reg_i': 20, 'method': 'als', 'reg_u': 10, 'n_epochs': 5}}, {'bsl_options': {'reg_i': 20, 'method': 'als', 'reg_u': 10, 'n_epochs': 10}}, {'bsl_options': {'reg_i': 20, 'method': 'als', 'reg_u': 10, 'n_epochs': 20}}, {'bsl_options': {'reg_i': 20, 'method': 'als', 'reg_u': 15, 'n_epochs': 5}}, {'bsl_options': {'reg_i': 20, 'method': 'als', 'reg_u': 15, 'n_epochs': 10}}, {'bsl_options': {'reg_i': 20, 'method': 'als', 'reg_u': 15, 'n_epochs': 20}}, {'bsl_options': {'reg_i': 20, 'method': 'als', 'reg_u': 20, 'n_epochs': 5}}, {'bsl_options': {'reg_i': 20, 'method': 'als', 'reg_u': 20, 'n_epochs': 10}}, {'bsl_options': {'reg_i': 20, 'method': 'als', 'reg_u': 20, 'n_epochs': 20}}]\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>method</th>\n",
       "      <th>n_epochs</th>\n",
       "      <th>reg_i</th>\n",
       "      <th>reg_u</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.941916</td>\n",
       "      <td>als</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.941916</td>\n",
       "      <td>als</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.941916</td>\n",
       "      <td>als</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.942123</td>\n",
       "      <td>als</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.942123</td>\n",
       "      <td>als</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.942123</td>\n",
       "      <td>als</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.942422</td>\n",
       "      <td>als</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.942422</td>\n",
       "      <td>als</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.942422</td>\n",
       "      <td>als</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.952976</td>\n",
       "      <td>als</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.952976</td>\n",
       "      <td>als</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.952976</td>\n",
       "      <td>als</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.953191</td>\n",
       "      <td>als</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.953191</td>\n",
       "      <td>als</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.953191</td>\n",
       "      <td>als</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.953488</td>\n",
       "      <td>als</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.953488</td>\n",
       "      <td>als</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.953488</td>\n",
       "      <td>als</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.960887</td>\n",
       "      <td>als</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.960887</td>\n",
       "      <td>als</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.960887</td>\n",
       "      <td>als</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.961104</td>\n",
       "      <td>als</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.961104</td>\n",
       "      <td>als</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.961104</td>\n",
       "      <td>als</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.961397</td>\n",
       "      <td>als</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.961397</td>\n",
       "      <td>als</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.961397</td>\n",
       "      <td>als</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        RMSE method  n_epochs  reg_i  reg_u\n",
       "18  0.941916    als         5     20     10\n",
       "19  0.941916    als        10     20     10\n",
       "20  0.941916    als        20     20     10\n",
       "9   0.942123    als         5     10     10\n",
       "10  0.942123    als        10     10     10\n",
       "11  0.942123    als        20     10     10\n",
       "0   0.942422    als         5      5     10\n",
       "1   0.942422    als        10      5     10\n",
       "2   0.942422    als        20      5     10\n",
       "21  0.952976    als         5     20     15\n",
       "22  0.952976    als        10     20     15\n",
       "23  0.952976    als        20     20     15\n",
       "12  0.953191    als         5     10     15\n",
       "13  0.953191    als        10     10     15\n",
       "14  0.953191    als        20     10     15\n",
       "3   0.953488    als         5      5     15\n",
       "4   0.953488    als        10      5     15\n",
       "5   0.953488    als        20      5     15\n",
       "24  0.960887    als         5     20     20\n",
       "25  0.960887    als        10     20     20\n",
       "26  0.960887    als        20     20     20\n",
       "15  0.961104    als         5     10     20\n",
       "16  0.961104    als        10     10     20\n",
       "17  0.961104    als        20     10     20\n",
       "6   0.961397    als         5      5     20\n",
       "7   0.961397    als        10      5     20\n",
       "8   0.961397    als        20      5     20"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Grid search for baseline - alternating least squares\n",
    "param_grid = {'bsl_options':{'method': ['als'], 'reg_i':[5,10,20], 'reg_u':[10,15,20], 'n_epochs':[5,10,20]}}\n",
    "gridsearch = GridSearch(BaselineOnly, param_grid, measures=['RMSE', 'MAE'], verbose=0)\n",
    "reader = Reader(rating_scale=(1,5))\n",
    "train = Dataset.load_from_df(train_500_20, reader)\n",
    "test = Dataset.load_from_df(test_500_20, reader)\n",
    "train.split(n_folds=3)\n",
    "gridsearch.evaluate(train)\n",
    "convert_grid_results_als(pd.DataFrame.from_dict(gridsearch.cv_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating for 500 users and 20 books; number of ratings: 4311\n",
      "Estimating biases using sgd...\n",
      "---Training: 0.015040397644042969 seconds ---\n",
      "---Testing: 0.0210568904876709 seconds ---\n",
      "RMSE: 0.8418\n",
      "MAE:  0.6653\n",
      "FCP:  0.6223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lohmu\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:3162: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "C:\\Users\\lohmu\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:3163: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n",
      "C:\\Users\\lohmu\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "C:\\Users\\lohmu\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "C:\\Users\\lohmu\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:1818: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPEARMAN:  0.26246319425252296\n",
      "\n",
      "Evaluating for 1000 users and 50 books; number of ratings: 19054\n",
      "Estimating biases using sgd...\n",
      "---Training: 0.12639832496643066 seconds ---\n",
      "---Testing: 0.10679054260253906 seconds ---\n",
      "RMSE: 0.8491\n",
      "MAE:  0.6632\n",
      "FCP:  0.6359\n",
      "SPEARMAN:  0.2826033295098762\n",
      "\n",
      "Evaluating for 2000 users and 50 books; number of ratings: 37100\n",
      "Estimating biases using sgd...\n",
      "---Training: 0.2462773323059082 seconds ---\n",
      "---Testing: 0.2077312469482422 seconds ---\n",
      "RMSE: 0.8432\n",
      "MAE:  0.6586\n",
      "FCP:  0.6421\n",
      "SPEARMAN:  0.2833207893730011\n",
      "\n",
      "Evaluating for 3000 users and 50 books; number of ratings: 54872\n",
      "Estimating biases using sgd...\n",
      "---Training: 0.4576988220214844 seconds ---\n",
      "---Testing: 0.5168583393096924 seconds ---\n",
      "RMSE: 0.8409\n",
      "MAE:  0.6564\n",
      "FCP:  0.6451\n",
      "SPEARMAN:  0.28965952881578805\n",
      "\n",
      "Evaluating for 5000 users and 75 books; number of ratings: 118800\n",
      "Estimating biases using sgd...\n",
      "---Training: 0.9623401165008545 seconds ---\n",
      "---Testing: 0.9470932483673096 seconds ---\n",
      "RMSE: 0.8468\n",
      "MAE:  0.6608\n",
      "FCP:  0.6411\n",
      "SPEARMAN:  0.2843447892408262\n",
      "\n",
      "Evaluating for 7500 users and 100 books; number of ratings: 210810\n",
      "Estimating biases using sgd...\n",
      "---Training: 1.7428500652313232 seconds ---\n",
      "---Testing: 1.5571908950805664 seconds ---\n",
      "RMSE: 0.8532\n",
      "MAE:  0.6670\n",
      "FCP:  0.6483\n",
      "SPEARMAN:  0.2909224257870984\n",
      "\n",
      "Evaluating for 10000 users and 100 books; number of ratings: 271422\n",
      "Estimating biases using sgd...\n",
      "---Training: 2.053258180618286 seconds ---\n",
      "---Testing: 2.0263288021087646 seconds ---\n",
      "RMSE: 0.8582\n",
      "MAE:  0.6711\n",
      "FCP:  0.6517\n",
      "SPEARMAN:  0.29717301706476096\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "#Combine train and test sets\n",
    "all_10000_100 = train_10000_100.append(test_10000_100)\n",
    "all_500_20 = train_500_20.append(test_500_20)\n",
    "all_2000_50 = train_2000_50.append(test_2000_50)\n",
    "\n",
    "\n",
    "def runBaselineSGD(dataframe, num_users, num_books):\n",
    "    print(\"\\nEvaluating for {} users and {} books; number of ratings: {}\".format(num_users, num_books, len(dataframe)))\n",
    "    \n",
    "    #set up reader and get data from dataframe\n",
    "    reader = Reader(rating_scale=(1, 5))\n",
    "    data = Dataset.load_from_df(dataframe[['user_id', 'book_id', 'rating']], reader)\n",
    "\n",
    "    #Split data into training set, testing set, and the anti-test set (all the items neither in test nor train)\n",
    "    trainset = data.build_full_trainset()\n",
    "    testset = trainset.build_testset()\n",
    "    antitestset = trainset.build_anti_testset()\n",
    "\n",
    "    #Set up algorithm\n",
    "    bsl_options = {'method': 'sgd', 'learning_rate':.005, 'n_epochs':20, 'reg':.01}\n",
    "    algo = BaselineOnly(bsl_options = bsl_options)\n",
    "    \n",
    "    #Capture start time\n",
    "    start_time = time.time()\n",
    "\n",
    "    #Train algorithm\n",
    "    algo.train(trainset)\n",
    "    \n",
    "    #Print training algorithm time\n",
    "    print(\"---Training: %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "    #Capture start time - test\n",
    "    start_time = time.time()\n",
    "    \n",
    "    #Get predictions\n",
    "    predictions = algo.test(testset)\n",
    "    \n",
    "    #Print training algorithm time\n",
    "    print(\"---Testing: %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "    #Evaluate accuracy measures\n",
    "    accuracy.rmse(predictions, verbose=True)\n",
    "    accuracy.mae(predictions, verbose=True)\n",
    "    accuracy.fcp(predictions, verbose=True)\n",
    "    print(\"SPEARMAN:  {}\".format(spearman(predictions)))\n",
    "    \n",
    "runBaselineSGD(all_500_20,500,20)\n",
    "runBaselineSGD(all_1000_50,1000,50)\n",
    "runBaselineSGD(all_2000_50,2000,50)\n",
    "runBaselineSGD(all_3000_50,3000,50)\n",
    "runBaselineSGD(all_5000_75,5000,75)\n",
    "runBaselineSGD(all_7500_100,7500,100)\n",
    "runBaselineSGD(all_10000_100,10000,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "def spearman(predictions):\n",
    "    dict_ratings = {}\n",
    "    spearmans = []\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        if float(true_r) and float(est) and not np.isnan(true_r) and not np.isnan(est):\n",
    "            if uid in dict_ratings.keys():\n",
    "                dict_ratings[uid][0].append(true_r)\n",
    "                dict_ratings[uid][1].append(est)\n",
    "            else:\n",
    "                dict_ratings[uid]=[[true_r],[est]]\n",
    "    for uid in dict_ratings.keys():\n",
    "        if len(dict_ratings[uid][0])>1:\n",
    "            spearman = spearmanr(dict_ratings[uid][0], dict_ratings[uid][1])[0]\n",
    "            if np.isnan(spearman) == False: # spearman is NaN if all true ratings are the same! exclude these\n",
    "                spearmans.append(spearman)\n",
    "    return np.mean(spearmans)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
