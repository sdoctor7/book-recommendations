{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##SVD and NMF with Surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import surprise\n",
    "from surprise import SVD\n",
    "from surprise import NMF\n",
    "from surprise import Dataset\n",
    "from surprise import evaluate, print_perf, GridSearch\n",
    "from surprise import Reader\n",
    "from surprise import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('../ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ratings = len(ratings)\n",
    "print('Number of ratings: {}'.format(n_ratings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# new start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_users_books(df, num_users, num_books):\n",
    "    user_counts = pd.DataFrame(df.user_id.value_counts()).sort_values('user_id', ascending=False)\n",
    "    top_10K_users = list(user_counts[0:num_users].index)\n",
    "    user_filtered_df = df[df.user_id.isin(top_10K_users)]\n",
    "    filtered_book_counts = pd.DataFrame(user_filtered_df.book_id.value_counts()).sort_values('book_id', ascending = False)\n",
    "    top_100_filtered_books = list(filtered_book_counts[0:num_books].index)\n",
    "    filtered_df = user_filtered_df[user_filtered_df.book_id.isin(top_100_filtered_books)]\n",
    "    print(\"New dataframe has {} users, {} items, and a sparsity of {}\".format(len(filtered_df.user_id.unique()),len(filtered_df.book_id.unique()),len(filtered_df)/(len(filtered_df.user_id.unique())*len(filtered_df.book_id.unique()))))\n",
    "    train, test = train_test_split(filtered_df, test_size = 0.2, random_state=42)\n",
    "    return filtered_df, train, test\n",
    "\n",
    "\n",
    "def get_all_subsets(df):\n",
    "    full_500_20, train_500_20, test_500_20 = pick_users_books(df, 500, 20)\n",
    "    full_1000_35, train_1000_35, test_1000_35 = pick_users_books(df, 1000, 35)\n",
    "    full_2000_50, train_2000_50, test_2000_50 = pick_users_books(df, 2000, 50)\n",
    "    full_5000_70, train_5000_70, test_5000_70 = pick_users_books(df, 5000, 70)\n",
    "    full_7500_85, train_7500_85, test_7500_85 = pick_users_books(df, 7500, 85)\n",
    "    full_10000_100, train_10000_100, test_10000_100 = pick_users_books(df, 10000, 100)\n",
    "    return full_500_20, train_500_20, test_500_20, \\\n",
    "full_1000_35, train_1000_35, test_1000_35, \\\n",
    "full_2000_50, train_2000_50, test_2000_50, \\\n",
    "full_5000_70, train_5000_70, test_5000_70, \\\n",
    "full_7500_85, train_7500_85, test_7500_85, \\\n",
    "full_10000_100, train_10000_100, test_10000_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New dataframe has 487 users, 20 items, and a sparsity of 0.44260780287474333\n",
      "New dataframe has 985 users, 35 items, and a sparsity of 0.4041189267585207\n",
      "New dataframe has 1981 users, 50 items, and a sparsity of 0.3745583038869258\n",
      "New dataframe has 4980 users, 70 items, and a sparsity of 0.32403614457831326\n",
      "New dataframe has 7479 users, 85 items, and a sparsity of 0.2953682074514523\n",
      "New dataframe has 9980 users, 100 items, and a sparsity of 0.2719659318637275\n"
     ]
    }
   ],
   "source": [
    "full_500_20, train_500_20, test_500_20, \\\n",
    "full_1000_35, train_1000_35, test_1000_35, \\\n",
    "full_2000_50, train_2000_50, test_2000_50, \\\n",
    "full_5000_70, train_5000_70, test_5000_70, \\\n",
    "full_7500_85, train_7500_85, test_7500_85, \\\n",
    "full_10000_100, train_10000_100, test_10000_100 = get_all_subsets(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# marika functions\n",
    "\n",
    "def spearman(predictions):\n",
    "    dict_ratings = {}\n",
    "    spearmans = []\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        if float(true_r) and float(est) and not np.isnan(true_r) and not np.isnan(est):\n",
    "            if uid in dict_ratings.keys():\n",
    "                dict_ratings[uid][0].append(true_r)\n",
    "                dict_ratings[uid][1].append(est)\n",
    "            else:\n",
    "                dict_ratings[uid]=[[true_r],[est]]\n",
    "    for uid in dict_ratings.keys():\n",
    "        if len(dict_ratings[uid][0])>1:\n",
    "            spearman = spearmanr(dict_ratings[uid][0], dict_ratings[uid][1])[0]\n",
    "            if np.isnan(spearman) == False: # spearman is NaN if all true ratings are the same! exclude these\n",
    "                spearmans.append(spearman)\n",
    "    return np.mean(spearmans)\n",
    "\n",
    "def get_top_n(predictions, n=10):\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n\n",
    "\n",
    "def calc_item_coverage(top_n, num_books):\n",
    "    bookset = set()\n",
    "    for book in top_n.keys():\n",
    "        for pair in top_n[book]:\n",
    "            bookset.add(pair[0])\n",
    "    return float(len(bookset))/num_books"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional iterations of the SVD algorithm (‘n_epochs’) had a clear, positive impact on performance (lower RMSE and MAE) as did additional factors (‘n_factors’), though to a lesser extent. We also tried biased vs. non-biased and found that adding a bias term for users and items always performed better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SVD Grid Search run. The following sets of paramters were tested:\n",
    "\n",
    "param_grid = {'n_factors': [100,150],'n_epochs': [20,40], 'lr_all': [0.015,0.03,0.045],\n",
    "              'reg_all': [0.025,0.05,0.075]}\n",
    "\n",
    "param_grid = {'n_factors': [150],'n_epochs': [40], 'lr_all': [0.01,0.02,0.03],\n",
    "              'reg_all': [0.05,0.075,0.1]}\n",
    "\n",
    "param_grid = {'n_factors': [125,150,175],'n_epochs': [30,40,50],\\\n",
    "              'lr_all': [0.0225],'reg_all': [0.08]}\n",
    "\n",
    "param_grid = {'n_factors': [160,180,200],'n_epochs': [45,55,65],\\\n",
    "              'lr_all': [0.0225],'reg_all': [0.08]}\n",
    "\n",
    "param_grid = {'n_factors': [150],'n_epochs': [40], 'lr_all': [0.015],\n",
    "              'reg_all': [.005,0.01,0.015,0.02,0.025,0.03,\\\n",
    "                          0.035,0.04,0.045,0.05,0.055, 0.06,\\\n",
    "                         0.065,0.07,0.075,0.08,0.085, 0.09,\\\n",
    "                         0.095,0.1,0.105,0.11,0.115, 0.12,\\\n",
    "                         0.125,0.13,0.135,0.14,0.145, 0.15]}\n",
    "\n",
    "param_grid = {'n_factors': [150],'n_epochs': [40],\\\n",
    "              'lr_all': [0.0025,0.005,0.0075,\\\n",
    "                         0.01,0.0125,0.015,0.0175,\\\n",
    "                         0.02,0.0225,0.025,0.0275,\\\n",
    "                         0.03,0.0325,0.035,0.0375,0.04],\n",
    "              'reg_all': [0.08]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'n_factors': 200, 'n_epochs': 50, 'lr_all': 0.0225, 'reg_all': 0.08}]\n",
      "------------\n",
      "Parameters combination 1 of 1\n",
      "params:  {'n_factors': 200, 'n_epochs': 50, 'lr_all': 0.0225, 'reg_all': 0.08}\n",
      "------------\n",
      "Mean RMSE: 0.8525\n",
      "Mean MAE : 0.6605\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "# SVD grid search\n",
    "\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "param_grid = {'n_factors': [100,150,200],'n_epochs': [50],\\\n",
    "              'lr_all': [0.0225],'reg_all': [0.08]}\n",
    "\n",
    "grid_search = GridSearch(SVD, param_grid, measures=[u'rmse', u'mae'], verbose=1)\n",
    "\n",
    "sur_data = Dataset.load_from_df(train_10000_100[['user_id','book_id','rating']], reader)\n",
    "sur_data.split(3)  # data can now be used normally\n",
    "\n",
    "grid_search.evaluate(sur_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after copying and pasting the above output to a txt file, i used the following code to\n",
    "# read the output and create a table with all the different runs and their corresponding\n",
    "# RMSE and MAE values\n",
    "\n",
    "result_df = pd.DataFrame(columns=['lr_all', 'n_epochs', 'n_factors', 'reg_all','RMSE','MAE'])\n",
    "\n",
    "file = open('../SVD_reg_plot.txt', 'r') \n",
    "for line in file:\n",
    "    if line[0:9] == 'Mean RMSE':\n",
    "        new_dict['RMSE'] = float(line.split(\":\")[1])\n",
    "    if line[0:8] == 'Mean MAE':\n",
    "        new_dict['MAE'] = float(line.split(\":\")[1])\n",
    "#         if new_dict['biased'] == False:\n",
    "#             new_dict['biased'] = 0\n",
    "#         else:\n",
    "#             new_dict['biased'] = 1\n",
    "        result_df = pd.concat([result_df,pd.DataFrame([new_dict])])\n",
    "    if line[0:7] == 'params:':\n",
    "        new_dict = ast.literal_eval(line.split(\"params:  \")[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rate at which the algorithm learns (lr_all) and the size of the regularization term (reg_all) had a less clear impact on performance. It seems that with a slower learning rate, a higher penalty (regularization parameter) works better, and vice versa. After investigating some of the grid search outputs, we settled on a number of factors and epochs, which have a lower impact on accuracy, in order to test regularization and learning rate more granularly. The following plots show how regularization and learning rate affect the RMSE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x15ad01dd8>"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEXCAYAAABVr8jJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXNw8eTjnnIubJw/nnHNx+z+4Di//xwmglAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11404a9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# to plot how changes in learning rate affect RMSE\n",
    "# requires the txt file from the SVD_learning rate run\n",
    "\n",
    "result_df.sort_values('lr_all').plot('lr_all','RMSE')\n",
    "plt.title('SVD: RMSE and Learning Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x174744d30>"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEXCAYAAACqIS9uAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEGPBb4wxIeb/AxF4UDEcuHTtAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x175426eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# to plot how changes in regularization affect RMSE\n",
    "# requires the txt file from the SVD_regularization rate run\n",
    "\n",
    "result_df.sort_values('reg_all').plot('reg_all','RMSE')\n",
    "plt.title('SVD: RMSE and Regularization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>lr_all</th>\n",
       "      <th>n_epochs</th>\n",
       "      <th>n_factors</th>\n",
       "      <th>reg_all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6610</td>\n",
       "      <td>0.8542</td>\n",
       "      <td>0.02</td>\n",
       "      <td>40</td>\n",
       "      <td>150</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6635</td>\n",
       "      <td>0.8552</td>\n",
       "      <td>0.02</td>\n",
       "      <td>40</td>\n",
       "      <td>150</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6622</td>\n",
       "      <td>0.8556</td>\n",
       "      <td>0.03</td>\n",
       "      <td>40</td>\n",
       "      <td>150</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6623</td>\n",
       "      <td>0.8560</td>\n",
       "      <td>0.03</td>\n",
       "      <td>40</td>\n",
       "      <td>150</td>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6620</td>\n",
       "      <td>0.8562</td>\n",
       "      <td>0.02</td>\n",
       "      <td>40</td>\n",
       "      <td>150</td>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6644</td>\n",
       "      <td>0.8569</td>\n",
       "      <td>0.03</td>\n",
       "      <td>40</td>\n",
       "      <td>150</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6658</td>\n",
       "      <td>0.8578</td>\n",
       "      <td>0.01</td>\n",
       "      <td>40</td>\n",
       "      <td>150</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6651</td>\n",
       "      <td>0.8597</td>\n",
       "      <td>0.01</td>\n",
       "      <td>40</td>\n",
       "      <td>150</td>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6721</td>\n",
       "      <td>0.8625</td>\n",
       "      <td>0.01</td>\n",
       "      <td>40</td>\n",
       "      <td>150</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      MAE    RMSE  lr_all n_epochs n_factors  reg_all\n",
       "0  0.6610  0.8542    0.02       40       150    0.075\n",
       "0  0.6635  0.8552    0.02       40       150    0.100\n",
       "0  0.6622  0.8556    0.03       40       150    0.075\n",
       "0  0.6623  0.8560    0.03       40       150    0.050\n",
       "0  0.6620  0.8562    0.02       40       150    0.050\n",
       "0  0.6644  0.8569    0.03       40       150    0.100\n",
       "0  0.6658  0.8578    0.01       40       150    0.075\n",
       "0  0.6651  0.8597    0.01       40       150    0.050\n",
       "0  0.6721  0.8625    0.01       40       150    0.100"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sorting the output by RMSE\n",
    "\n",
    "result_df.sort_values('RMSE').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD.\n",
      "\n",
      "------------\n",
      "Fold 1\n",
      "RMSE: 0.8579\n",
      "MAE:  0.6621\n",
      "------------\n",
      "Fold 2\n",
      "RMSE: 0.8506\n",
      "MAE:  0.6601\n",
      "------------\n",
      "Fold 3\n",
      "RMSE: 0.8515\n",
      "MAE:  0.6603\n",
      "------------\n",
      "------------\n",
      "Mean RMSE: 0.8533\n",
      "Mean MAE : 0.6608\n",
      "------------\n",
      "------------\n",
      "        Fold 1  Fold 2  Fold 3  Mean    \n",
      "RMSE    0.8579  0.8506  0.8515  0.8533  \n",
      "MAE     0.6621  0.6601  0.6603  0.6608  \n",
      "0:01:25.785883\n"
     ]
    }
   ],
   "source": [
    "# single SVD run\n",
    "\n",
    "start_time = (datetime.datetime.now())\n",
    "\n",
    "# A reader is still needed but only the rating_scale param is requiered.\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "sur_data = Dataset.load_from_df(full_10000_100[['user_id','book_id','rating']], reader)\n",
    "sur_data.split(3)  # data can now be used normally\n",
    "\n",
    "algo = SVD(n_factors =  150, n_epochs = 50, lr_all =  0.0225,\n",
    "              reg_all =  0.08)\n",
    "\n",
    "# Evaluate performances of our algorithm on the dataset.\n",
    "perf = evaluate(algo, sur_data, measures=['RMSE', 'MAE'])\n",
    "\n",
    "print_perf(perf)\n",
    "\n",
    "stop_time = (datetime.datetime.now())\n",
    "print(stop_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output for accuracy and time tables\n",
    "\n",
    "def SVD_test(sample):\n",
    "    #Capture start time\n",
    "    start_time = time.time()\n",
    "\n",
    "    #set up reader and get data from dataframe\n",
    "    reader = Reader(rating_scale=(1, 5))\n",
    "    data = Dataset.load_from_df(sample[['user_id', 'book_id', 'rating']], reader)\n",
    "\n",
    "    #Split data into training set, testing set, and the anti-test set (all the items neither in test nor train)\n",
    "    trainset = data.build_full_trainset()\n",
    "    testset = trainset.build_testset()\n",
    "    antitestset = trainset.build_anti_testset()\n",
    "\n",
    "    #Set up algorithm\n",
    "\n",
    "    algo = SVD(n_factors =  200, n_epochs = 50, lr_all =  0.0225,\n",
    "                  reg_all =  0.08)\n",
    "\n",
    "    #Train algorithm\n",
    "    algo.train(trainset)\n",
    "\n",
    "        #Print algorithm time\n",
    "        \n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    next_time = time.time()\n",
    "    \n",
    "    #Get predictions\n",
    "    predictions = algo.test(testset)\n",
    "\n",
    "    print(\"--- %s seconds ---\" % (time.time() - next_time))\n",
    "    \n",
    "    #Evaluate accuracy measures\n",
    "    accuracy.rmse(predictions, verbose=True)\n",
    "    accuracy.mae(predictions, verbose=True)\n",
    "    accuracy.fcp(predictions, verbose=True)\n",
    "    spman = spearman(predictions)\n",
    "    print(\"SPEARMAN:  {}\".format(spman))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.9952630996704102 seconds ---\n",
      "RMSE: 0.2795\n",
      "MAE:  0.2156\n",
      "FCP:  0.9602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marksalama/anaconda/lib/python3.6/site-packages/numpy/lib/function_base.py:3003: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/Users/marksalama/anaconda/lib/python3.6/site-packages/numpy/lib/function_base.py:3004: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n",
      "/Users/marksalama/anaconda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/marksalama/anaconda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/marksalama/anaconda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1818: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPEARMAN:  0.8746993336176473\n",
      "--- 0.30649590492248535 seconds ---\n",
      "--- 3.2643730640411377 seconds ---\n",
      "RMSE: 0.3475\n",
      "MAE:  0.2645\n",
      "FCP:  0.9620\n",
      "SPEARMAN:  0.8688140280272801\n",
      "--- 0.604604959487915 seconds ---\n",
      "--- 8.65052318572998 seconds ---\n",
      "RMSE: 0.4013\n",
      "MAE:  0.3054\n",
      "FCP:  0.9574\n",
      "SPEARMAN:  0.8686647295845686\n",
      "--- 1.3693420886993408 seconds ---\n",
      "--- 28.251965284347534 seconds ---\n",
      "RMSE: 0.4522\n",
      "MAE:  0.3447\n",
      "FCP:  0.9513\n",
      "SPEARMAN:  0.8622719182611005\n",
      "--- 4.674900054931641 seconds ---\n",
      "--- 48.53049826622009 seconds ---\n",
      "RMSE: 0.4753\n",
      "MAE:  0.3645\n",
      "FCP:  0.9452\n",
      "SPEARMAN:  0.8583539076590213\n",
      "--- 7.165470361709595 seconds ---\n",
      "--- 69.29260802268982 seconds ---\n",
      "RMSE: 0.4972\n",
      "MAE:  0.3824\n",
      "FCP:  0.9385\n",
      "SPEARMAN:  0.849745270100673\n",
      "--- 9.73905897140503 seconds ---\n"
     ]
    }
   ],
   "source": [
    "for i in (full_500_20,full_1000_35,full_2000_50,full_5000_70,full_7500_85,full_10000_100):\n",
    "    SVD_test(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NMF Grid Search run. The following sets of paramters were tested:\n",
    "param_grid = {'n_factors': [15,30],'n_epochs': [40,70], 'lr_bu': [0.004,0.008], 'lr_bi': [0.004,0.008],\n",
    "              'reg_pu': [0.05,0.07], 'reg_qi': [0.05,0.07]}\n",
    "\n",
    "param_grid = {'n_factors': [30,45],'n_epochs': [70,100], 'lr_bu': [0.007,0.008], 'lr_bi': [0.007,0.008],\n",
    "              'reg_pu': [0.07,0.08], 'reg_qi': [0.07,0.08]}\n",
    "\n",
    "\n",
    "param_grid = {'n_factors': [40,50],'n_epochs': [60,80], 'lr_bu': [0.0075,0.0085], 'lr_bi': [0.0075,0.0085],\n",
    "              'reg_pu': [0.075,0.085], 'reg_qi': [0.075,0.085]}\n",
    "\n",
    "param_grid = {'n_factors': [50,60],'n_epochs': [80,90], 'lr_bu': [0.0085], 'lr_bi': [0.0085],\n",
    "              'reg_pu': [0.085], 'reg_qi': [0.085]}\n",
    "\n",
    "param_grid = {'n_factors': [60],'n_epochs': [80], 'lr_bu': [0.01,0.011,0.012],\n",
    "              'lr_bi': [0.01,0.011,0.012], 'reg_pu': [0.05,0.07,0.09],\n",
    "              'reg_qi': [0.05,0.07,0.09]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing a similar grid search with NMF through Surprise quickly revealed a few insights. Starting from the defaults, higher latent factors and higher iterations nearly always outperformed At least in the set of initial parameters tested, the regularization term is more important than the learning rate. Further tests showed that as with SVD, higher regularization pairs better with lower learning rates, and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.01, 'lr_bi': 0.01, 'reg_pu': 0.05, 'reg_qi': 0.05}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.01, 'lr_bi': 0.01, 'reg_pu': 0.05, 'reg_qi': 0.07}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.01, 'lr_bi': 0.01, 'reg_pu': 0.05, 'reg_qi': 0.09}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.01, 'lr_bi': 0.01, 'reg_pu': 0.07, 'reg_qi': 0.05}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.01, 'lr_bi': 0.01, 'reg_pu': 0.07, 'reg_qi': 0.07}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.01, 'lr_bi': 0.01, 'reg_pu': 0.07, 'reg_qi': 0.09}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.01, 'lr_bi': 0.01, 'reg_pu': 0.09, 'reg_qi': 0.05}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.01, 'lr_bi': 0.01, 'reg_pu': 0.09, 'reg_qi': 0.07}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.01, 'lr_bi': 0.01, 'reg_pu': 0.09, 'reg_qi': 0.09}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.01, 'lr_bi': 0.011, 'reg_pu': 0.05, 'reg_qi': 0.05}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.01, 'lr_bi': 0.011, 'reg_pu': 0.05, 'reg_qi': 0.07}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.01, 'lr_bi': 0.011, 'reg_pu': 0.05, 'reg_qi': 0.09}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.01, 'lr_bi': 0.011, 'reg_pu': 0.07, 'reg_qi': 0.05}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.01, 'lr_bi': 0.011, 'reg_pu': 0.07, 'reg_qi': 0.07}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.01, 'lr_bi': 0.011, 'reg_pu': 0.07, 'reg_qi': 0.09}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.01, 'lr_bi': 0.011, 'reg_pu': 0.09, 'reg_qi': 0.05}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.01, 'lr_bi': 0.011, 'reg_pu': 0.09, 'reg_qi': 0.07}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.01, 'lr_bi': 0.011, 'reg_pu': 0.09, 'reg_qi': 0.09}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.01, 'lr_bi': 0.012, 'reg_pu': 0.05, 'reg_qi': 0.05}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.01, 'lr_bi': 0.012, 'reg_pu': 0.05, 'reg_qi': 0.07}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.01, 'lr_bi': 0.012, 'reg_pu': 0.05, 'reg_qi': 0.09}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.01, 'lr_bi': 0.012, 'reg_pu': 0.07, 'reg_qi': 0.05}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.01, 'lr_bi': 0.012, 'reg_pu': 0.07, 'reg_qi': 0.07}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.01, 'lr_bi': 0.012, 'reg_pu': 0.07, 'reg_qi': 0.09}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.01, 'lr_bi': 0.012, 'reg_pu': 0.09, 'reg_qi': 0.05}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.01, 'lr_bi': 0.012, 'reg_pu': 0.09, 'reg_qi': 0.07}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.01, 'lr_bi': 0.012, 'reg_pu': 0.09, 'reg_qi': 0.09}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.011, 'lr_bi': 0.01, 'reg_pu': 0.05, 'reg_qi': 0.05}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.011, 'lr_bi': 0.01, 'reg_pu': 0.05, 'reg_qi': 0.07}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.011, 'lr_bi': 0.01, 'reg_pu': 0.05, 'reg_qi': 0.09}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.011, 'lr_bi': 0.01, 'reg_pu': 0.07, 'reg_qi': 0.05}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.011, 'lr_bi': 0.01, 'reg_pu': 0.07, 'reg_qi': 0.07}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.011, 'lr_bi': 0.01, 'reg_pu': 0.07, 'reg_qi': 0.09}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.011, 'lr_bi': 0.01, 'reg_pu': 0.09, 'reg_qi': 0.05}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.011, 'lr_bi': 0.01, 'reg_pu': 0.09, 'reg_qi': 0.07}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.011, 'lr_bi': 0.01, 'reg_pu': 0.09, 'reg_qi': 0.09}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.011, 'lr_bi': 0.011, 'reg_pu': 0.05, 'reg_qi': 0.05}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.011, 'lr_bi': 0.011, 'reg_pu': 0.05, 'reg_qi': 0.07}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.011, 'lr_bi': 0.011, 'reg_pu': 0.05, 'reg_qi': 0.09}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.011, 'lr_bi': 0.011, 'reg_pu': 0.07, 'reg_qi': 0.05}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.011, 'lr_bi': 0.011, 'reg_pu': 0.07, 'reg_qi': 0.07}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.011, 'lr_bi': 0.011, 'reg_pu': 0.07, 'reg_qi': 0.09}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.011, 'lr_bi': 0.011, 'reg_pu': 0.09, 'reg_qi': 0.05}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.011, 'lr_bi': 0.011, 'reg_pu': 0.09, 'reg_qi': 0.07}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.011, 'lr_bi': 0.011, 'reg_pu': 0.09, 'reg_qi': 0.09}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.011, 'lr_bi': 0.012, 'reg_pu': 0.05, 'reg_qi': 0.05}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.011, 'lr_bi': 0.012, 'reg_pu': 0.05, 'reg_qi': 0.07}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.011, 'lr_bi': 0.012, 'reg_pu': 0.05, 'reg_qi': 0.09}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.011, 'lr_bi': 0.012, 'reg_pu': 0.07, 'reg_qi': 0.05}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.011, 'lr_bi': 0.012, 'reg_pu': 0.07, 'reg_qi': 0.07}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.011, 'lr_bi': 0.012, 'reg_pu': 0.07, 'reg_qi': 0.09}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.011, 'lr_bi': 0.012, 'reg_pu': 0.09, 'reg_qi': 0.05}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.011, 'lr_bi': 0.012, 'reg_pu': 0.09, 'reg_qi': 0.07}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.011, 'lr_bi': 0.012, 'reg_pu': 0.09, 'reg_qi': 0.09}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.012, 'lr_bi': 0.01, 'reg_pu': 0.05, 'reg_qi': 0.05}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.012, 'lr_bi': 0.01, 'reg_pu': 0.05, 'reg_qi': 0.07}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.012, 'lr_bi': 0.01, 'reg_pu': 0.05, 'reg_qi': 0.09}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.012, 'lr_bi': 0.01, 'reg_pu': 0.07, 'reg_qi': 0.05}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.012, 'lr_bi': 0.01, 'reg_pu': 0.07, 'reg_qi': 0.07}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.012, 'lr_bi': 0.01, 'reg_pu': 0.07, 'reg_qi': 0.09}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.012, 'lr_bi': 0.01, 'reg_pu': 0.09, 'reg_qi': 0.05}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.012, 'lr_bi': 0.01, 'reg_pu': 0.09, 'reg_qi': 0.07}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.012, 'lr_bi': 0.01, 'reg_pu': 0.09, 'reg_qi': 0.09}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.012, 'lr_bi': 0.011, 'reg_pu': 0.05, 'reg_qi': 0.05}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.012, 'lr_bi': 0.011, 'reg_pu': 0.05, 'reg_qi': 0.07}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.012, 'lr_bi': 0.011, 'reg_pu': 0.05, 'reg_qi': 0.09}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.012, 'lr_bi': 0.011, 'reg_pu': 0.07, 'reg_qi': 0.05}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.012, 'lr_bi': 0.011, 'reg_pu': 0.07, 'reg_qi': 0.07}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.012, 'lr_bi': 0.011, 'reg_pu': 0.07, 'reg_qi': 0.09}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.012, 'lr_bi': 0.011, 'reg_pu': 0.09, 'reg_qi': 0.05}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.012, 'lr_bi': 0.011, 'reg_pu': 0.09, 'reg_qi': 0.07}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.012, 'lr_bi': 0.011, 'reg_pu': 0.09, 'reg_qi': 0.09}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.012, 'lr_bi': 0.012, 'reg_pu': 0.05, 'reg_qi': 0.05}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.012, 'lr_bi': 0.012, 'reg_pu': 0.05, 'reg_qi': 0.07}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.012, 'lr_bi': 0.012, 'reg_pu': 0.05, 'reg_qi': 0.09}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.012, 'lr_bi': 0.012, 'reg_pu': 0.07, 'reg_qi': 0.05}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.012, 'lr_bi': 0.012, 'reg_pu': 0.07, 'reg_qi': 0.07}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.012, 'lr_bi': 0.012, 'reg_pu': 0.07, 'reg_qi': 0.09}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.012, 'lr_bi': 0.012, 'reg_pu': 0.09, 'reg_qi': 0.05}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.012, 'lr_bi': 0.012, 'reg_pu': 0.09, 'reg_qi': 0.07}, {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.012, 'lr_bi': 0.012, 'reg_pu': 0.09, 'reg_qi': 0.09}]\n",
      "------------\n",
      "Parameters combination 1 of 81\n",
      "params:  {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.01, 'lr_bi': 0.01, 'reg_pu': 0.05, 'reg_qi': 0.05}\n",
      "------------\n",
      "Mean RMSE: 0.9144\n",
      "Mean MAE : 0.6803\n",
      "------------\n",
      "------------\n",
      "Parameters combination 2 of 81\n",
      "params:  {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.01, 'lr_bi': 0.01, 'reg_pu': 0.05, 'reg_qi': 0.07}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "Mean RMSE: 0.8933\n",
      "Mean MAE : 0.6778\n",
      "------------\n",
      "------------\n",
      "Parameters combination 3 of 81\n",
      "params:  {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.01, 'lr_bi': 0.01, 'reg_pu': 0.05, 'reg_qi': 0.09}\n",
      "------------\n",
      "Mean RMSE: 0.8857\n",
      "Mean MAE : 0.6791\n",
      "------------\n",
      "------------\n",
      "Parameters combination 4 of 81\n",
      "params:  {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.01, 'lr_bi': 0.01, 'reg_pu': 0.07, 'reg_qi': 0.05}\n",
      "------------\n",
      "Mean RMSE: 0.8938\n",
      "Mean MAE : 0.6783\n",
      "------------\n",
      "------------\n",
      "Parameters combination 5 of 81\n",
      "params:  {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.01, 'lr_bi': 0.01, 'reg_pu': 0.07, 'reg_qi': 0.07}\n",
      "------------\n",
      "Mean RMSE: 0.8855\n",
      "Mean MAE : 0.6827\n",
      "------------\n",
      "------------\n",
      "Parameters combination 6 of 81\n",
      "params:  {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.01, 'lr_bi': 0.01, 'reg_pu': 0.07, 'reg_qi': 0.09}\n",
      "------------\n",
      "Mean RMSE: 0.8828\n",
      "Mean MAE : 0.6866\n",
      "------------\n",
      "------------\n",
      "Parameters combination 7 of 81\n",
      "params:  {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.01, 'lr_bi': 0.01, 'reg_pu': 0.09, 'reg_qi': 0.05}\n",
      "------------\n",
      "Mean RMSE: 0.8868\n",
      "Mean MAE : 0.6825\n",
      "------------\n",
      "------------\n",
      "Parameters combination 8 of 81\n",
      "params:  {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.01, 'lr_bi': 0.01, 'reg_pu': 0.09, 'reg_qi': 0.07}\n",
      "------------\n",
      "Mean RMSE: 0.8851\n",
      "Mean MAE : 0.6886\n",
      "------------\n",
      "------------\n",
      "Parameters combination 9 of 81\n",
      "params:  {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.01, 'lr_bi': 0.01, 'reg_pu': 0.09, 'reg_qi': 0.09}\n",
      "------------\n",
      "Mean RMSE: 0.8834\n",
      "Mean MAE : 0.6920\n",
      "------------\n",
      "------------\n",
      "Parameters combination 10 of 81\n",
      "params:  {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.01, 'lr_bi': 0.011, 'reg_pu': 0.05, 'reg_qi': 0.05}\n",
      "------------\n",
      "Mean RMSE: 0.9132\n",
      "Mean MAE : 0.6793\n",
      "------------\n",
      "------------\n",
      "Parameters combination 11 of 81\n",
      "params:  {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.01, 'lr_bi': 0.011, 'reg_pu': 0.05, 'reg_qi': 0.07}\n",
      "------------\n",
      "Mean RMSE: 0.8941\n",
      "Mean MAE : 0.6782\n",
      "------------\n",
      "------------\n",
      "Parameters combination 12 of 81\n",
      "params:  {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.01, 'lr_bi': 0.011, 'reg_pu': 0.05, 'reg_qi': 0.09}\n",
      "------------\n",
      "Mean RMSE: 0.8835\n",
      "Mean MAE : 0.6778\n",
      "------------\n",
      "------------\n",
      "Parameters combination 13 of 81\n",
      "params:  {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.01, 'lr_bi': 0.011, 'reg_pu': 0.07, 'reg_qi': 0.05}\n",
      "------------\n",
      "Mean RMSE: 0.8928\n",
      "Mean MAE : 0.6779\n",
      "------------\n",
      "------------\n",
      "Parameters combination 14 of 81\n",
      "params:  {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.01, 'lr_bi': 0.011, 'reg_pu': 0.07, 'reg_qi': 0.07}\n",
      "------------\n",
      "Mean RMSE: 0.8830\n",
      "Mean MAE : 0.6807\n",
      "------------\n",
      "------------\n",
      "Parameters combination 15 of 81\n",
      "params:  {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.01, 'lr_bi': 0.011, 'reg_pu': 0.07, 'reg_qi': 0.09}\n",
      "------------\n",
      "Mean RMSE: 0.8826\n",
      "Mean MAE : 0.6864\n",
      "------------\n",
      "------------\n",
      "Parameters combination 16 of 81\n",
      "params:  {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.01, 'lr_bi': 0.011, 'reg_pu': 0.09, 'reg_qi': 0.05}\n",
      "------------\n",
      "Mean RMSE: 0.8872\n",
      "Mean MAE : 0.6828\n",
      "------------\n",
      "------------\n",
      "Parameters combination 17 of 81\n",
      "params:  {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.01, 'lr_bi': 0.011, 'reg_pu': 0.09, 'reg_qi': 0.07}\n",
      "------------\n",
      "Mean RMSE: 0.8832\n",
      "Mean MAE : 0.6875\n",
      "------------\n",
      "------------\n",
      "Parameters combination 18 of 81\n",
      "params:  {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.01, 'lr_bi': 0.011, 'reg_pu': 0.09, 'reg_qi': 0.09}\n",
      "------------\n",
      "Mean RMSE: 0.8821\n",
      "Mean MAE : 0.6909\n",
      "------------\n",
      "------------\n",
      "Parameters combination 19 of 81\n",
      "params:  {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.01, 'lr_bi': 0.012, 'reg_pu': 0.05, 'reg_qi': 0.05}\n",
      "------------\n",
      "Mean RMSE: 0.9151\n",
      "Mean MAE : 0.6804\n",
      "------------\n",
      "------------\n",
      "Parameters combination 20 of 81\n",
      "params:  {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.01, 'lr_bi': 0.012, 'reg_pu': 0.05, 'reg_qi': 0.07}\n",
      "------------\n",
      "Mean RMSE: 0.8937\n",
      "Mean MAE : 0.6777\n",
      "------------\n",
      "------------\n",
      "Parameters combination 21 of 81\n",
      "params:  {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.01, 'lr_bi': 0.012, 'reg_pu': 0.05, 'reg_qi': 0.09}\n",
      "------------\n",
      "Mean RMSE: 0.8870\n",
      "Mean MAE : 0.6803\n",
      "------------\n",
      "------------\n",
      "Parameters combination 22 of 81\n",
      "params:  {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.01, 'lr_bi': 0.012, 'reg_pu': 0.07, 'reg_qi': 0.05}\n",
      "------------\n",
      "Mean RMSE: 0.8932\n",
      "Mean MAE : 0.6779\n",
      "------------\n",
      "------------\n",
      "Parameters combination 23 of 81\n",
      "params:  {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.01, 'lr_bi': 0.012, 'reg_pu': 0.07, 'reg_qi': 0.07}\n",
      "------------\n",
      "Mean RMSE: 0.8851\n",
      "Mean MAE : 0.6819\n",
      "------------\n",
      "------------\n",
      "Parameters combination 24 of 81\n",
      "params:  {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.01, 'lr_bi': 0.012, 'reg_pu': 0.07, 'reg_qi': 0.09}\n",
      "------------\n",
      "Mean RMSE: 0.8826\n",
      "Mean MAE : 0.6863\n",
      "------------\n",
      "------------\n",
      "Parameters combination 25 of 81\n",
      "params:  {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.01, 'lr_bi': 0.012, 'reg_pu': 0.09, 'reg_qi': 0.05}\n",
      "------------\n",
      "Mean RMSE: 0.8866\n",
      "Mean MAE : 0.6819\n",
      "------------\n",
      "------------\n",
      "Parameters combination 26 of 81\n",
      "params:  {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.01, 'lr_bi': 0.012, 'reg_pu': 0.09, 'reg_qi': 0.07}\n",
      "------------\n",
      "Mean RMSE: 0.8837\n",
      "Mean MAE : 0.6877\n",
      "------------\n",
      "------------\n",
      "Parameters combination 27 of 81\n",
      "params:  {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.01, 'lr_bi': 0.012, 'reg_pu': 0.09, 'reg_qi': 0.09}\n",
      "------------\n",
      "Mean RMSE: 0.8820\n",
      "Mean MAE : 0.6908\n",
      "------------\n",
      "------------\n",
      "Parameters combination 28 of 81\n",
      "params:  {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.011, 'lr_bi': 0.01, 'reg_pu': 0.05, 'reg_qi': 0.05}\n",
      "------------\n",
      "Mean RMSE: 0.9160\n",
      "Mean MAE : 0.6816\n",
      "------------\n",
      "------------\n",
      "Parameters combination 29 of 81\n",
      "params:  {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.011, 'lr_bi': 0.01, 'reg_pu': 0.05, 'reg_qi': 0.07}\n",
      "------------\n",
      "Mean RMSE: 0.8935\n",
      "Mean MAE : 0.6783\n",
      "------------\n",
      "------------\n",
      "Parameters combination 30 of 81\n",
      "params:  {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.011, 'lr_bi': 0.01, 'reg_pu': 0.05, 'reg_qi': 0.09}\n",
      "------------\n",
      "Mean RMSE: 0.8859\n",
      "Mean MAE : 0.6795\n",
      "------------\n",
      "------------\n",
      "Parameters combination 31 of 81\n",
      "params:  {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.011, 'lr_bi': 0.01, 'reg_pu': 0.07, 'reg_qi': 0.05}\n",
      "------------\n",
      "Mean RMSE: 0.8937\n",
      "Mean MAE : 0.6783\n",
      "------------\n",
      "------------\n",
      "Parameters combination 32 of 81\n",
      "params:  {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.011, 'lr_bi': 0.01, 'reg_pu': 0.07, 'reg_qi': 0.07}\n",
      "------------\n",
      "Mean RMSE: 0.8853\n",
      "Mean MAE : 0.6824\n",
      "------------\n",
      "------------\n",
      "Parameters combination 33 of 81\n",
      "params:  {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.011, 'lr_bi': 0.01, 'reg_pu': 0.07, 'reg_qi': 0.09}\n",
      "------------\n",
      "Mean RMSE: 0.8823\n",
      "Mean MAE : 0.6858\n",
      "------------\n",
      "------------\n",
      "Parameters combination 34 of 81\n",
      "params:  {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.011, 'lr_bi': 0.01, 'reg_pu': 0.09, 'reg_qi': 0.05}\n",
      "------------\n",
      "Mean RMSE: 0.8871\n",
      "Mean MAE : 0.6833\n",
      "------------\n",
      "------------\n",
      "Parameters combination 35 of 81\n",
      "params:  {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.011, 'lr_bi': 0.01, 'reg_pu': 0.09, 'reg_qi': 0.07}\n",
      "------------\n",
      "Mean RMSE: 0.8831\n",
      "Mean MAE : 0.6871\n",
      "------------\n",
      "------------\n",
      "Parameters combination 36 of 81\n",
      "params:  {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.011, 'lr_bi': 0.01, 'reg_pu': 0.09, 'reg_qi': 0.09}\n",
      "------------\n",
      "Mean RMSE: 0.8818\n",
      "Mean MAE : 0.6907\n",
      "------------\n",
      "------------\n",
      "Parameters combination 37 of 81\n",
      "params:  {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.011, 'lr_bi': 0.011, 'reg_pu': 0.05, 'reg_qi': 0.05}\n",
      "------------\n",
      "Mean RMSE: 0.9133\n",
      "Mean MAE : 0.6797\n",
      "------------\n",
      "------------\n",
      "Parameters combination 38 of 81\n",
      "params:  {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.011, 'lr_bi': 0.011, 'reg_pu': 0.05, 'reg_qi': 0.07}\n",
      "------------\n",
      "Mean RMSE: 0.8928\n",
      "Mean MAE : 0.6769\n",
      "------------\n",
      "------------\n",
      "Parameters combination 39 of 81\n",
      "params:  {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.011, 'lr_bi': 0.011, 'reg_pu': 0.05, 'reg_qi': 0.09}\n",
      "------------\n",
      "Mean RMSE: 0.8870\n",
      "Mean MAE : 0.6811\n",
      "------------\n",
      "------------\n",
      "Parameters combination 40 of 81\n",
      "params:  {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.011, 'lr_bi': 0.011, 'reg_pu': 0.07, 'reg_qi': 0.05}\n",
      "------------\n",
      "Mean RMSE: 0.8933\n",
      "Mean MAE : 0.6782\n",
      "------------\n",
      "------------\n",
      "Parameters combination 41 of 81\n",
      "params:  {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.011, 'lr_bi': 0.011, 'reg_pu': 0.07, 'reg_qi': 0.07}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "Mean RMSE: 0.8849\n",
      "Mean MAE : 0.6816\n",
      "------------\n",
      "------------\n",
      "Parameters combination 42 of 81\n",
      "params:  {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.011, 'lr_bi': 0.011, 'reg_pu': 0.07, 'reg_qi': 0.09}\n",
      "------------\n",
      "Mean RMSE: 0.8824\n",
      "Mean MAE : 0.6860\n",
      "------------\n",
      "------------\n",
      "Parameters combination 43 of 81\n",
      "params:  {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.011, 'lr_bi': 0.011, 'reg_pu': 0.09, 'reg_qi': 0.05}\n",
      "------------\n",
      "Mean RMSE: 0.8878\n",
      "Mean MAE : 0.6835\n",
      "------------\n",
      "------------\n",
      "Parameters combination 44 of 81\n",
      "params:  {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.011, 'lr_bi': 0.011, 'reg_pu': 0.09, 'reg_qi': 0.07}\n",
      "------------\n",
      "Mean RMSE: 0.8834\n",
      "Mean MAE : 0.6877\n",
      "------------\n",
      "------------\n",
      "Parameters combination 45 of 81\n",
      "params:  {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.011, 'lr_bi': 0.011, 'reg_pu': 0.09, 'reg_qi': 0.09}\n",
      "------------\n",
      "Mean RMSE: 0.8823\n",
      "Mean MAE : 0.6915\n",
      "------------\n",
      "------------\n",
      "Parameters combination 46 of 81\n",
      "params:  {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.011, 'lr_bi': 0.012, 'reg_pu': 0.05, 'reg_qi': 0.05}\n",
      "------------\n",
      "Mean RMSE: 0.9135\n",
      "Mean MAE : 0.6793\n",
      "------------\n",
      "------------\n",
      "Parameters combination 47 of 81\n",
      "params:  {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.011, 'lr_bi': 0.012, 'reg_pu': 0.05, 'reg_qi': 0.07}\n",
      "------------\n",
      "Mean RMSE: 0.8922\n",
      "Mean MAE : 0.6756\n",
      "------------\n",
      "------------\n",
      "Parameters combination 48 of 81\n",
      "params:  {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.011, 'lr_bi': 0.012, 'reg_pu': 0.05, 'reg_qi': 0.09}\n",
      "------------\n",
      "Mean RMSE: 0.8862\n",
      "Mean MAE : 0.6798\n",
      "------------\n",
      "------------\n",
      "Parameters combination 49 of 81\n",
      "params:  {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.011, 'lr_bi': 0.012, 'reg_pu': 0.07, 'reg_qi': 0.05}\n",
      "------------\n",
      "Mean RMSE: 0.8936\n",
      "Mean MAE : 0.6786\n",
      "------------\n",
      "------------\n",
      "Parameters combination 50 of 81\n",
      "params:  {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.011, 'lr_bi': 0.012, 'reg_pu': 0.07, 'reg_qi': 0.07}\n",
      "------------\n",
      "Mean RMSE: 0.8854\n",
      "Mean MAE : 0.6827\n",
      "------------\n",
      "------------\n",
      "Parameters combination 51 of 81\n",
      "params:  {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.011, 'lr_bi': 0.012, 'reg_pu': 0.07, 'reg_qi': 0.09}\n",
      "------------\n",
      "Mean RMSE: 0.8812\n",
      "Mean MAE : 0.6848\n",
      "------------\n",
      "------------\n",
      "Parameters combination 52 of 81\n",
      "params:  {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.011, 'lr_bi': 0.012, 'reg_pu': 0.09, 'reg_qi': 0.05}\n",
      "------------\n",
      "Mean RMSE: 0.8890\n",
      "Mean MAE : 0.6830\n",
      "------------\n",
      "------------\n",
      "Parameters combination 53 of 81\n",
      "params:  {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.011, 'lr_bi': 0.012, 'reg_pu': 0.09, 'reg_qi': 0.07}\n",
      "------------\n",
      "Mean RMSE: 0.8846\n",
      "Mean MAE : 0.6880\n",
      "------------\n",
      "------------\n",
      "Parameters combination 54 of 81\n",
      "params:  {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.011, 'lr_bi': 0.012, 'reg_pu': 0.09, 'reg_qi': 0.09}\n",
      "------------\n",
      "Mean RMSE: 0.8814\n",
      "Mean MAE : 0.6897\n",
      "------------\n",
      "------------\n",
      "Parameters combination 55 of 81\n",
      "params:  {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.012, 'lr_bi': 0.01, 'reg_pu': 0.05, 'reg_qi': 0.05}\n",
      "------------\n",
      "Mean RMSE: 0.9159\n",
      "Mean MAE : 0.6816\n",
      "------------\n",
      "------------\n",
      "Parameters combination 56 of 81\n",
      "params:  {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.012, 'lr_bi': 0.01, 'reg_pu': 0.05, 'reg_qi': 0.07}\n",
      "------------\n",
      "Mean RMSE: 0.8920\n",
      "Mean MAE : 0.6758\n",
      "------------\n",
      "------------\n",
      "Parameters combination 57 of 81\n",
      "params:  {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.012, 'lr_bi': 0.01, 'reg_pu': 0.05, 'reg_qi': 0.09}\n",
      "------------\n",
      "Mean RMSE: 0.8848\n",
      "Mean MAE : 0.6792\n",
      "------------\n",
      "------------\n",
      "Parameters combination 58 of 81\n",
      "params:  {'n_factors': 60, 'n_epochs': 80, 'lr_bu': 0.012, 'lr_bi': 0.01, 'reg_pu': 0.07, 'reg_qi': 0.05}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-222-7d1b5d541ee6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0msur_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# data can now be used normally\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msur_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/marksalama/anaconda/lib/python3.6/site-packages/surprise/evaluate.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    204\u001b[0m             evaluate_results = evaluate(algo_instance, data,\n\u001b[1;32m    205\u001b[0m                                         \u001b[0mmeasures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeasures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m                                         verbose=(self.verbose == 2))\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0;31m# measures as keys and folds average as values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marksalama/anaconda/lib/python3.6/site-packages/surprise/evaluate.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(algo, data, measures, with_dump, dump_dir, verbose)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m# train and test algorithm. Keep all rating predictions in a list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marksalama/anaconda/lib/python3.6/site-packages/surprise/prediction_algorithms/matrix_factorization.pyx\u001b[0m in \u001b[0;36msurprise.prediction_algorithms.matrix_factorization.NMF.train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Users/marksalama/anaconda/lib/python3.6/site-packages/surprise/prediction_algorithms/matrix_factorization.pyx\u001b[0m in \u001b[0;36msurprise.prediction_algorithms.matrix_factorization.NMF.sgd\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Users/marksalama/anaconda/lib/python3.6/site-packages/surprise/dataset.py\u001b[0m in \u001b[0;36mall_ratings\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_ratings\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mur\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mu_ratings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild_testset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#NMF Grid Search\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "param_grid = {'n_factors': [60],'n_epochs': [80], 'lr_bu': [0.01,0.011,0.012], 'lr_bi': [0.01,0.011,0.012], 'reg_pu': [0.05,0.07,0.09], 'reg_qi': [0.05,0.07,0.09]}\n",
    "\n",
    "grid_search = GridSearch(NMF, param_grid, measures=[u'rmse', u'mae'], verbose=1)\n",
    "\n",
    "sur_data = Dataset.load_from_df(train_10000_100[['user_id','book_id','rating']], reader)\n",
    "sur_data.split(3)  # data can now be used normally\n",
    "\n",
    "grid_search.evaluate(sur_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after copying and pasting the above output to a txt file, i used the following code to\n",
    "# read the output and create a table with all the different runs and their corresponding\n",
    "# RMSE and MAE values\n",
    "\n",
    "\n",
    "result_df = pd.DataFrame(columns=['n_epochs', 'n_factors', 'lr_bu', 'lr_bi' , 'reg_pu', 'reg_qi', 'RMSE','MAE'])\n",
    "\n",
    "file = open('../NMF_primary5.txt', 'r') \n",
    "for line in file:\n",
    "    if line[0:9] == 'Mean RMSE':\n",
    "        new_dict['RMSE'] = float(line.split(\":\")[1])\n",
    "    if line[0:8] == 'Mean MAE':\n",
    "        new_dict['MAE'] = float(line.split(\":\")[1])\n",
    "#         if new_dict['biased'] == False:\n",
    "#             new_dict['biased'] = 0\n",
    "#         else:\n",
    "#             new_dict['biased'] = 1\n",
    "        result_df = pd.concat([result_df,pd.DataFrame([new_dict])])\n",
    "    if line[0:7] == 'params:':\n",
    "        new_dict = ast.literal_eval(line.split(\"params:  \")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>lr_bi</th>\n",
       "      <th>lr_bu</th>\n",
       "      <th>n_epochs</th>\n",
       "      <th>n_factors</th>\n",
       "      <th>reg_pu</th>\n",
       "      <th>reg_qi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6848</td>\n",
       "      <td>0.8812</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.011</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6897</td>\n",
       "      <td>0.8814</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.011</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6907</td>\n",
       "      <td>0.8818</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.011</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6908</td>\n",
       "      <td>0.8820</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.010</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6909</td>\n",
       "      <td>0.8821</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.010</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6858</td>\n",
       "      <td>0.8823</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.011</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6915</td>\n",
       "      <td>0.8823</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6860</td>\n",
       "      <td>0.8824</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6864</td>\n",
       "      <td>0.8826</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.010</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6863</td>\n",
       "      <td>0.8826</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.010</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      MAE    RMSE  lr_bi  lr_bu n_epochs n_factors  reg_pu  reg_qi\n",
       "0  0.6848  0.8812  0.012  0.011       80        60    0.07    0.09\n",
       "0  0.6897  0.8814  0.012  0.011       80        60    0.09    0.09\n",
       "0  0.6907  0.8818  0.010  0.011       80        60    0.09    0.09\n",
       "0  0.6908  0.8820  0.012  0.010       80        60    0.09    0.09\n",
       "0  0.6909  0.8821  0.011  0.010       80        60    0.09    0.09\n",
       "0  0.6858  0.8823  0.010  0.011       80        60    0.07    0.09\n",
       "0  0.6915  0.8823  0.011  0.011       80        60    0.09    0.09\n",
       "0  0.6860  0.8824  0.011  0.011       80        60    0.07    0.09\n",
       "0  0.6864  0.8826  0.011  0.010       80        60    0.07    0.09\n",
       "0  0.6863  0.8826  0.012  0.010       80        60    0.07    0.09"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results sorted by RMSE\n",
    "result_df.sort_values('RMSE').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output for accuracy and timing tables using optimal parameters established above\n",
    "\n",
    "def NMF_test(sample):\n",
    "    result_dict = {}\n",
    "    #Capture start time\n",
    "    start_time = time.time()\n",
    "\n",
    "    #set up reader and get data from dataframe\n",
    "    reader = Reader(rating_scale=(1, 5))\n",
    "    data = Dataset.load_from_df(sample[['user_id', 'book_id', 'rating']], reader)\n",
    "\n",
    "    #Split data into training set, testing set, and the anti-test set (all the items neither in test nor train)\n",
    "    trainset = data.build_full_trainset()\n",
    "    testset = trainset.build_testset()\n",
    "    antitestset = trainset.build_anti_testset()\n",
    "\n",
    "    #Set up algorithm\n",
    "\n",
    "    algo = NMF(n_factors = 60, n_epochs=  80, lr_bu = 0.0085, lr_bi = 0.00085,\n",
    "              reg_pu = 0.085, reg_qi = 0.085)\n",
    "\n",
    "    #Train algorithm\n",
    "    algo.train(trainset)\n",
    "\n",
    "        #Print algorithm time\n",
    "        \n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    \n",
    "    result_dict['time_train'] = (time.time() - start_time)\n",
    "\n",
    "    next_time = time.time()\n",
    "    \n",
    "    #Get predictions\n",
    "    predictions = algo.test(testset)\n",
    "\n",
    "    print(\"--- %s seconds ---\" % (time.time() - next_time))\n",
    "    \n",
    "    result_dict['time_test'] = (time.time() - next_time)\n",
    "    \n",
    "    #Evaluate accuracy measures\n",
    "#     accuracy.rmse(predictions, verbose=True)\n",
    "#     accuracy.mae(predictions, verbose=True)\n",
    "#     accuracy.fcp(predictions, verbose=True)\n",
    "#     spman = spearman(predictions)\n",
    "#     print(\"SPEARMAN:  {}\".format(spman))\n",
    "\n",
    "    result_dict['RMSE'] = float(accuracy.rmse(predictions, verbose=True))\n",
    "    result_dict['MAE'] = float(accuracy.mae(predictions, verbose=True))\n",
    "    result_dict['FCP'] = float(accuracy.fcp(predictions, verbose=True))\n",
    "    result_dict['Spearman'] = float(spearman(predictions))\n",
    "    \n",
    "    return result_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.4971\n",
      "MAE:  0.3823\n",
      "FCP:  0.9389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marksalama/anaconda/lib/python3.6/site-packages/numpy/lib/function_base.py:3003: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/Users/marksalama/anaconda/lib/python3.6/site-packages/numpy/lib/function_base.py:3004: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n",
      "/Users/marksalama/anaconda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/marksalama/anaconda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/marksalama/anaconda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1818: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n"
     ]
    }
   ],
   "source": [
    "result_dict = {}\n",
    "result_dict['RMSE'] = accuracy.rmse(predictions, verbose=True)\n",
    "result_dict['MAE'] = accuracy.mae(predictions, verbose=True)\n",
    "result_dict['FCP'] = accuracy.fcp(predictions, verbose=True)\n",
    "result_dict['Spearman'] = spearman(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.4971\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4970722566524826"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mark = accuracy.rmse(predictions, verbose=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "35\n",
      "50\n",
      "70\n",
      "85\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "for i,x in enumerate(book_list):\n",
    "    print (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.8606929779052734 seconds ---\n",
      "--- 0.03710293769836426 seconds ---\n",
      "RMSE: 0.3470\n",
      "MAE:  0.2536\n",
      "FCP:  0.9267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marksalama/anaconda/lib/python3.6/site-packages/numpy/lib/function_base.py:3003: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/Users/marksalama/anaconda/lib/python3.6/site-packages/numpy/lib/function_base.py:3004: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n",
      "/Users/marksalama/anaconda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/marksalama/anaconda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/marksalama/anaconda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1818: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2.813260793685913 seconds ---\n",
      "--- 0.07932686805725098 seconds ---\n",
      "RMSE: 0.4486\n",
      "MAE:  0.3334\n",
      "FCP:  0.9357\n",
      "--- 7.327859878540039 seconds ---\n",
      "--- 1.057865858078003 seconds ---\n",
      "RMSE: 0.5223\n",
      "MAE:  0.3934\n",
      "FCP:  0.9129\n"
     ]
    }
   ],
   "source": [
    "output_df = pd.DataFrame(columns=['books','time_train', 'RMSE', 'MAE', 'Spearman', 'time_test'])\n",
    "book_list = [20,35,50,70,85,100]\n",
    "\n",
    "# test_sets = [full_500_20,full_1000_35,full_2000_50,full_5000_70,full_7500_85,full_10000_100]\n",
    "test_sets = [full_500_20,full_1000_35,full_2000_50]\n",
    "\n",
    "for i,x in enumerate(test_sets):\n",
    "    result_dict = NMF_test(x)\n",
    "#     result_dict['books'] = book_list[i]\n",
    "    output_df = pd.concat([output_df,pd.DataFrame([result_dict])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>books</th>\n",
       "      <th>time_train</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Spearman</th>\n",
       "      <th>time_test</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  books time_train RMSE  MAE Spearman time_test     0\n",
       "0   NaN        NaN  NaN  NaN      NaN       NaN  None\n",
       "0   NaN        NaN  NaN  NaN      NaN       NaN  None\n",
       "0   NaN        NaN  NaN  NaN      NaN       NaN  None"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COVERAGE FOR TOP 5: 0.93\n",
      "COVERAGE FOR TOP 10: 0.98\n",
      "COVERAGE FOR TOP 15: 1.0\n",
      "COVERAGE FOR TOP 20: 1.0\n"
     ]
    }
   ],
   "source": [
    "# select the algorithm and then run item coverage\n",
    "\n",
    "algo = NMF(n_factors = 60, n_epochs=  80, lr_bu = 0.0085, lr_bi = 0.00085,\n",
    "              reg_pu = 0.085, reg_qi = 0.085)\n",
    "\n",
    "# algo = SVD(n_factors =  200, n_epochs = 50, lr_all =  0.0225,\n",
    "#                   reg_all =  0.08)\n",
    "\n",
    "return_coverage(algo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coverage function\n",
    "def return_coverage(algo):\n",
    "    #Get coverage for different values of n on the largest subset\n",
    "\n",
    "    n_ratings = len(full_10000_100)\n",
    "    num_users = len(full_10000_100.user_id.unique())\n",
    "    num_books = len(full_10000_100.book_id.unique())\n",
    "\n",
    "    #set up reader and get data from dataframe\n",
    "    reader = Reader(rating_scale=(1, 5))\n",
    "    data = Dataset.load_from_df(full_10000_100[['user_id', 'book_id', 'rating']], reader)\n",
    "\n",
    "    #Split data into training set, testing set, and the anti-test set (all the items neither in test nor train)\n",
    "    trainset = data.build_full_trainset()\n",
    "    antitestset = trainset.build_anti_testset()\n",
    "\n",
    "#     #Set up algorithm\n",
    "#     algo = algo\n",
    "\n",
    "    #Train algorithm\n",
    "    algo.train(trainset)\n",
    "\n",
    "    #Estimate unknown ratings\n",
    "    true_predictions = algo.test(antitestset)\n",
    "\n",
    "    #Get top n recommendations\n",
    "    ns=[5,10,15,20]\n",
    "\n",
    "    for n in ns:\n",
    "        top_n = get_top_n(true_predictions, n)\n",
    "        print(\"COVERAGE FOR TOP {}: {}\".format(n,calc_item_coverage(top_n, num_books)))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
